{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "genre_classfication_snn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ief7murLJDW9"
      },
      "source": [
        "# Genre Classification with spiking neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwYhnbTdKE14"
      },
      "source": [
        "## Install SpikingJelly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZPOtEVkp7oO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e39cc1a-5710-4ba6-8d57-38501b69f4b2"
      },
      "source": [
        "!pip install spikingjelly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.6-py3-none-any.whl (177 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 92 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 102 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 112 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 122 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 143 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 153 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 163 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 174 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 177 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (1.19.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (0.10.0+cu102)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (4.62.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->spikingjelly) (3.7.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->spikingjelly) (1.15.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->spikingjelly) (7.1.2)\n",
            "Installing collected packages: spikingjelly\n",
            "Successfully installed spikingjelly-0.0.0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1u75F2AKICP"
      },
      "source": [
        "## Get data from Google Drive\n",
        "Click on the link, and follow the steps to get authenticated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDTUs2Qdu2M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604c079a-a74f-4a87-9877-92e249972567"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1C6rKHGr-0A8mbzdTbS8Yn_yhtqYMuFl8\"})\n",
        "downloaded.GetContentFile('paper_spectrograms.zip')\n",
        "!unzip paper_spectrograms.zip\n",
        "!rm -rf __MACOSX\n",
        "!rm -f paper_spectrograms.zip\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1rsSEkMksELO073o0x5hl_e7pYjlPdyEv\"})\n",
        "downloaded.GetContentFile('paper_labels.npy')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  paper_spectrograms.zip\n",
            "  inflating: genres_numpy.npy        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VxVYUpJ8gabq"
      },
      "source": [
        "# import all necessary modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp\n",
        "import numpy as np\n",
        "import spikingjelly.clock_driven.neuron as neurons\n",
        "from spikingjelly.clock_driven import functional\n",
        "from spikingjelly.clock_driven.layer import SeqToANNContainer\n",
        "from spikingjelly.clock_driven.surrogate import Sigmoid\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import gc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6G5d2u-ZMrh"
      },
      "source": [
        "# set variables such as device (gpu or cpu), batch_size and timesteps\n",
        "batch_size = 8\n",
        "timesteps = 4\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZvCdsxRilR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f7f6d6-c7d9-42c5-9853-a906c342e5df"
      },
      "source": [
        "X_melspec = np.load(\"./genres_numpy.npy\")\n",
        "X_melspec = np.expand_dims(np.moveaxis(X_melspec, 2, 1), axis=-1)\n",
        "X_melspec = np.moveaxis(X_melspec, -1, 1)\n",
        "X_melspec = torch.log(torch.Tensor(X_melspec) + 1)\n",
        "\n",
        "y = np.load(\"./paper_labels.npy\").squeeze()\n",
        "y = torch.Tensor(y).type(torch.long)\n",
        "\n",
        "X_melspec, y = shuffle(X_melspec, y, random_state=0)\n",
        "\n",
        "print(X_melspec.shape)    #expected: (999, 1, 647, 128)\n",
        "print(y.shape)    #expected (999,)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([999, 1, 647, 128])\n",
            "torch.Size([999])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GYV3e_9LDop"
      },
      "source": [
        "## The Model\n",
        "![picture](https://drive.google.com/uc?export=view&id=1D6074PAg44CdAyxv1qkXdorhRcQNRxwr)\n",
        "![picture](https://drive.google.com/uc?export=view&id=1OhdyfepB1TjU06iSpc-8ikkgHGXjoEqo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfBde5HcqJHJ"
      },
      "source": [
        "alpha = 2\n",
        "v_thresh = 0.75\n",
        "tau = 1.5\n",
        "\n",
        "class ExternalNet(nn.Module):\n",
        "    def __init__(self, alpha, V_th, tau, neuron_type):\n",
        "        super().__init__()\n",
        "        self.num_dense_blocks = 3\n",
        "        self.num_conv_filters = 32\n",
        "        self.num_classes = 10\n",
        "\n",
        "        if neuron_type == 'lif':\n",
        "            self.lifs = nn.ModuleList([neurons.MultiStepLIFNode(\n",
        "                surrogate_function = Sigmoid(alpha=alpha, spiking=True),\n",
        "                tau = tau,\n",
        "                v_threshold=V_th,\n",
        "                detach_reset=True\n",
        "            ) for i in range(self.num_dense_blocks + 2)])\n",
        "        else:\n",
        "            self.lifs = nn.ModuleList([neurons.MultiStepIFNode(\n",
        "                surrogate_function = Sigmoid(alpha=alpha, spiking=True),\n",
        "                v_threshold=V_th,\n",
        "                detach_reset=True\n",
        "            ) for i in range(self.num_dense_blocks + 2)])\n",
        "\n",
        "        self.initial_layers = SeqToANNContainer(\n",
        "            nn.Conv2d(1, self.num_conv_filters, 3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(self.num_conv_filters),\n",
        "            nn.MaxPool2d((4, 1)),\n",
        "        )\n",
        "\n",
        "        self.inception_blocks = nn.ModuleList()\n",
        "        for i in range(self.num_dense_blocks):\n",
        "            self.inception_blocks.append(self.get_inception_block(i))\n",
        "        \n",
        "        self.final_layers = SeqToANNContainer(\n",
        "            nn.BatchNorm2d((4*self.num_dense_blocks+1)*self.num_conv_filters),\n",
        "            nn.Conv2d((4*self.num_dense_blocks+1)*self.num_conv_filters, self.num_conv_filters, 1),\n",
        "            nn.AvgPool2d(self.num_conv_filters),\n",
        "            nn.BatchNorm2d(self.num_conv_filters),\n",
        "        )\n",
        "        self.avgpool = SeqToANNContainer(nn.AdaptiveAvgPool2d((1, 1)))\n",
        "        self.final_linear = nn.Linear(self.num_conv_filters, self.num_classes)\n",
        "\n",
        "    def base_conv_block(self, kernel_size, block_num):\n",
        "        num_channels = self.num_conv_filters * (4*block_num + 1)\n",
        "        return SeqToANNContainer(\n",
        "            nn.BatchNorm2d(num_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_channels, self.num_conv_filters, kernel_size, padding=\"same\")\n",
        "        )\n",
        "    \n",
        "    def base_conv_block_32(self, kernel_size):\n",
        "        return SeqToANNContainer(\n",
        "            nn.BatchNorm2d(self.num_conv_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self.num_conv_filters, self.num_conv_filters, kernel_size, padding=\"same\")\n",
        "        )\n",
        "    \n",
        "    def get_inception_block(self, block_num):\n",
        "        return nn.ModuleList(\n",
        "            modules=[\n",
        "                self.base_conv_block(1, block_num),\n",
        "                nn.Sequential(\n",
        "                    self.base_conv_block(1, block_num),\n",
        "                    self.base_conv_block_32(3),\n",
        "                ),\n",
        "                nn.Sequential(\n",
        "                    self.base_conv_block(1, block_num),\n",
        "                    self.base_conv_block_32(5),\n",
        "                ),\n",
        "                nn.Sequential(\n",
        "                    SeqToANNContainer(nn.MaxPool2d(3, stride=1, padding=1)),\n",
        "                    self.base_conv_block(1, block_num)\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.initial_layers(x)\n",
        "        x = self.lifs[0](x)\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        for (i, block) in enumerate(self.inception_blocks):\n",
        "            out = torch.cat((block[0](x), block[1](x), block[2](x), block[3](x)), dim=2)\n",
        "            out = self.lifs[i+1](out)\n",
        "            x = torch.cat([x, out], dim=2)\n",
        "            del out\n",
        "        x = self.final_layers(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.lifs[-1](x)\n",
        "        x = torch.flatten(x, start_dim=2).mean(dim=0)\n",
        "        x = self.final_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsAIEXbdwhVU"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzGzzl7Dji6J"
      },
      "source": [
        "def num_correct(model_out, labels):\n",
        "    y_pred = torch.argmax(model_out, 1).to(device)\n",
        "    return sum(y_pred == labels).detach().item()\n",
        "\n",
        "def train_one_epoch(epoch, net, train_loader,\n",
        "                    loss_fn, optimizer, acc_func, scaler,\n",
        "                    train_loss_hist, train_acc_hist):\n",
        "    print(f\"======== Epoch: {epoch+1} ========\")\n",
        "    net.train()\n",
        "    for batch_, (x, y_true) in enumerate(train_loader):\n",
        "        batch = batch_ + 1\n",
        "        # stack the input over t timesteps\n",
        "        x = torch.stack([x for _ in range(timesteps)])\n",
        "        x, y_true = x.to(device), y_true.to(device)\n",
        "        with amp.autocast():\n",
        "            y_pred = net(x)\n",
        "            train_loss = loss_fn(y_pred, y_true)\n",
        "        train_acc = acc_func(y_pred, y_true)/batch_size\n",
        "        del x, y_true, y_pred\n",
        "\n",
        "        # update weights\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(train_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        functional.reset_net(net)\n",
        "        train_loss = train_loss.detach().item()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            print(f\"Batch {batch}: Loss = {train_loss}, accuracy = {train_acc}\")\n",
        "            train_loss_hist.append(train_loss)\n",
        "            train_acc_hist.append(train_acc)\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "def validation(epoch, net, val_loader, loss_fn, acc_func, val_loss_hist, val_acc_hist):\n",
        "    print(\"Validation: \", end=\"\")\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_acc, model_preds = 0, 0, torch.Tensor([])\n",
        "        for x, y_true in val_loader:\n",
        "            x, y_true = x.to(device, non_blocking=True), y_true.to(device, non_blocking=True)\n",
        "            x = torch.stack([x for _ in range(timesteps)])\n",
        "            with amp.autocast():\n",
        "                y_pred = net(x)\n",
        "                val_loss_temp = loss_fn(y_pred, y_true)\n",
        "            \n",
        "            val_loss += val_loss_temp.detach().item()\n",
        "            val_acc += acc_func(y_pred, y_true)\n",
        "\n",
        "            functional.reset_net(net)\n",
        "            y_pred = y_pred.detach().cpu()\n",
        "            model_preds = torch.cat((model_preds, torch.argmax(y_pred, dim=1)))\n",
        "\n",
        "        #last batch containis 4 samples, so has 4/16 = 0.25 weightage\n",
        "        val_loss /= len(val_loader) - 1 + 4/16\n",
        "        val_acc /= 119 # 100 samples in validation\n",
        "        val_loss_hist.append(val_loss)\n",
        "        val_acc_hist.append(val_acc)\n",
        "        print(f\"Loss = {val_loss}, accuracy = {val_acc}\")\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    return val_loss, val_acc, model_preds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO2YgFJJtDog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ec27a3-1482-4362-98a9-0d31762d0039"
      },
      "source": [
        "epochs = 100\n",
        "alpha, V_th, tau, neuron_type = 2.0, 0.75, 1.25, 'lif'\n",
        "\n",
        "X_train, y_train = X_melspec[:880], y[:880]\n",
        "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "X_test, y_test = X_melspec[880:], y[880:]\n",
        "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "# define net, loss function, optimiizer, and scheduler\n",
        "net = ExternalNet(alpha=alpha, V_th=V_th, tau=tau, neuron_type=neuron_type).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
        "#scaler for memory management\n",
        "scaler = amp.GradScaler()\n",
        "\n",
        "train_loss_hist, train_acc_hist, val_loss_hist, val_acc_hist = [], [], [], []\n",
        "max_val_acc, min_val_loss, best_preds = 0, 0, None\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_one_epoch(epoch, net, train_loader,\n",
        "                    loss_fn, optimizer, num_correct, scaler,\n",
        "                    train_loss_hist, train_acc_hist)\n",
        "    val_loss, val_acc, preds = validation(epoch, net, test_loader, loss_fn, num_correct, val_loss_hist, val_acc_hist)\n",
        "    if val_acc >= max_val_acc:\n",
        "        max_val_acc = val_acc\n",
        "        min_val_loss = val_loss\n",
        "        best_preds = preds\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "print(\"Best accuracy achieved:\", max_val_acc)\n",
        "print(\"Corresponding loss: \", min_val_loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== Epoch: 1 ========\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10: Loss = 2.16845703125, accuracy = 0.25\n",
            "Batch 20: Loss = 2.1492919921875, accuracy = 0.25\n",
            "Batch 30: Loss = 2.0369873046875, accuracy = 0.25\n",
            "Batch 40: Loss = 1.6343994140625, accuracy = 0.375\n",
            "Batch 50: Loss = 1.81158447265625, accuracy = 0.25\n",
            "Batch 60: Loss = 1.71160888671875, accuracy = 0.25\n",
            "Batch 70: Loss = 1.59613037109375, accuracy = 0.5\n",
            "Batch 80: Loss = 1.87249755859375, accuracy = 0.25\n",
            "Batch 90: Loss = 1.6602783203125, accuracy = 0.375\n",
            "Batch 100: Loss = 1.63128662109375, accuracy = 0.375\n",
            "Batch 110: Loss = 1.80682373046875, accuracy = 0.5\n",
            "Validation: Loss = 1.9081780366730272, accuracy = 0.3865546218487395\n",
            "======== Epoch: 2 ========\n",
            "Batch 10: Loss = 1.46026611328125, accuracy = 0.5\n",
            "Batch 20: Loss = 1.6534423828125, accuracy = 0.5\n",
            "Batch 30: Loss = 1.90679931640625, accuracy = 0.5\n",
            "Batch 40: Loss = 1.78033447265625, accuracy = 0.625\n",
            "Batch 50: Loss = 1.3926239013671875, accuracy = 0.375\n",
            "Batch 60: Loss = 2.3389892578125, accuracy = 0.125\n",
            "Batch 70: Loss = 1.484588623046875, accuracy = 0.625\n",
            "Batch 80: Loss = 1.79351806640625, accuracy = 0.375\n",
            "Batch 90: Loss = 1.18304443359375, accuracy = 0.625\n",
            "Batch 100: Loss = 1.2756805419921875, accuracy = 0.5\n",
            "Batch 110: Loss = 1.401824951171875, accuracy = 0.375\n",
            "Validation: Loss = 1.6741417500010707, accuracy = 0.453781512605042\n",
            "======== Epoch: 3 ========\n",
            "Batch 10: Loss = 1.766082763671875, accuracy = 0.125\n",
            "Batch 20: Loss = 1.213623046875, accuracy = 0.5\n",
            "Batch 30: Loss = 1.1851348876953125, accuracy = 0.5\n",
            "Batch 40: Loss = 1.59405517578125, accuracy = 0.25\n",
            "Batch 50: Loss = 1.2100830078125, accuracy = 0.375\n",
            "Batch 60: Loss = 1.7255859375, accuracy = 0.5\n",
            "Batch 70: Loss = 1.935089111328125, accuracy = 0.25\n",
            "Batch 80: Loss = 1.9085693359375, accuracy = 0.125\n",
            "Batch 90: Loss = 0.927764892578125, accuracy = 0.75\n",
            "Batch 100: Loss = 1.4595279693603516, accuracy = 0.5\n",
            "Batch 110: Loss = 1.794921875, accuracy = 0.25\n",
            "Validation: Loss = 1.5456098589980811, accuracy = 0.453781512605042\n",
            "======== Epoch: 4 ========\n",
            "Batch 10: Loss = 2.3668212890625, accuracy = 0.375\n",
            "Batch 20: Loss = 1.308197021484375, accuracy = 0.625\n",
            "Batch 30: Loss = 1.1185302734375, accuracy = 0.5\n",
            "Batch 40: Loss = 1.7164955139160156, accuracy = 0.5\n",
            "Batch 50: Loss = 1.62664794921875, accuracy = 0.375\n",
            "Batch 60: Loss = 1.4637451171875, accuracy = 0.5\n",
            "Batch 70: Loss = 2.389251708984375, accuracy = 0.125\n",
            "Batch 80: Loss = 1.398895263671875, accuracy = 0.5\n",
            "Batch 90: Loss = 1.81695556640625, accuracy = 0.5\n",
            "Batch 100: Loss = 1.2680511474609375, accuracy = 0.375\n",
            "Batch 110: Loss = 0.9930877685546875, accuracy = 0.625\n",
            "Validation: Loss = 1.5253275653772187, accuracy = 0.5462184873949579\n",
            "======== Epoch: 5 ========\n",
            "Batch 10: Loss = 1.347991943359375, accuracy = 0.375\n",
            "Batch 20: Loss = 1.3392333984375, accuracy = 0.625\n",
            "Batch 30: Loss = 0.8350067138671875, accuracy = 0.75\n",
            "Batch 40: Loss = 1.1124343872070312, accuracy = 0.625\n",
            "Batch 50: Loss = 1.044586181640625, accuracy = 0.5\n",
            "Batch 60: Loss = 0.948944091796875, accuracy = 0.625\n",
            "Batch 70: Loss = 0.778045654296875, accuracy = 0.75\n",
            "Batch 80: Loss = 2.46710205078125, accuracy = 0.25\n",
            "Batch 90: Loss = 1.38623046875, accuracy = 0.625\n",
            "Batch 100: Loss = 1.1285400390625, accuracy = 0.5\n",
            "Batch 110: Loss = 1.6767196655273438, accuracy = 0.375\n",
            "Validation: Loss = 1.490002858011346, accuracy = 0.47058823529411764\n",
            "======== Epoch: 6 ========\n",
            "Batch 10: Loss = 1.2792510986328125, accuracy = 0.5\n",
            "Batch 20: Loss = 1.5175933837890625, accuracy = 0.375\n",
            "Batch 30: Loss = 1.3353271484375, accuracy = 0.625\n",
            "Batch 40: Loss = 1.6124706268310547, accuracy = 0.375\n",
            "Batch 50: Loss = 0.7270355224609375, accuracy = 0.75\n",
            "Batch 60: Loss = 0.7296905517578125, accuracy = 0.875\n",
            "Batch 70: Loss = 1.28546142578125, accuracy = 0.5\n",
            "Batch 80: Loss = 0.8857879638671875, accuracy = 0.75\n",
            "Batch 90: Loss = 1.168914794921875, accuracy = 0.625\n",
            "Batch 100: Loss = 1.3680419921875, accuracy = 0.375\n",
            "Batch 110: Loss = 1.0953598022460938, accuracy = 0.625\n",
            "Validation: Loss = 1.335495530513295, accuracy = 0.5714285714285714\n",
            "======== Epoch: 7 ========\n",
            "Batch 10: Loss = 0.9104499816894531, accuracy = 0.75\n",
            "Batch 20: Loss = 1.329254150390625, accuracy = 0.5\n",
            "Batch 30: Loss = 1.1328582763671875, accuracy = 0.75\n",
            "Batch 40: Loss = 1.324249267578125, accuracy = 0.5\n",
            "Batch 50: Loss = 1.111083984375, accuracy = 0.5\n",
            "Batch 60: Loss = 1.0659027099609375, accuracy = 0.5\n",
            "Batch 70: Loss = 1.5241851806640625, accuracy = 0.375\n",
            "Batch 80: Loss = 1.2408409118652344, accuracy = 0.5\n",
            "Batch 90: Loss = 1.40264892578125, accuracy = 0.5\n",
            "Batch 100: Loss = 1.681060791015625, accuracy = 0.25\n",
            "Batch 110: Loss = 1.6483154296875, accuracy = 0.375\n",
            "Validation: Loss = 1.4329233587833874, accuracy = 0.6134453781512605\n",
            "======== Epoch: 8 ========\n",
            "Batch 10: Loss = 1.1497344970703125, accuracy = 0.625\n",
            "Batch 20: Loss = 2.363250732421875, accuracy = 0.5\n",
            "Batch 30: Loss = 0.9716987609863281, accuracy = 0.625\n",
            "Batch 40: Loss = 1.3222007751464844, accuracy = 0.625\n",
            "Batch 50: Loss = 1.0134010314941406, accuracy = 0.5\n",
            "Batch 60: Loss = 1.618011474609375, accuracy = 0.5\n",
            "Batch 70: Loss = 1.24786376953125, accuracy = 0.5\n",
            "Batch 80: Loss = 1.3896331787109375, accuracy = 0.5\n",
            "Batch 90: Loss = 0.9509086608886719, accuracy = 0.75\n",
            "Batch 100: Loss = 1.23651123046875, accuracy = 0.5\n",
            "Batch 110: Loss = 1.0771102905273438, accuracy = 0.625\n",
            "Validation: Loss = 1.3078583625324987, accuracy = 0.6386554621848739\n",
            "======== Epoch: 9 ========\n",
            "Batch 10: Loss = 1.5520172119140625, accuracy = 0.25\n",
            "Batch 20: Loss = 1.42535400390625, accuracy = 0.375\n",
            "Batch 30: Loss = 0.96356201171875, accuracy = 0.75\n",
            "Batch 40: Loss = 1.07763671875, accuracy = 0.5\n",
            "Batch 50: Loss = 3.0488128662109375, accuracy = 0.25\n",
            "Batch 60: Loss = 1.0067901611328125, accuracy = 0.625\n",
            "Batch 70: Loss = 0.8309783935546875, accuracy = 0.75\n",
            "Batch 80: Loss = 0.7059783935546875, accuracy = 0.75\n",
            "Batch 90: Loss = 1.0904464721679688, accuracy = 0.625\n",
            "Batch 100: Loss = 1.136993408203125, accuracy = 0.5\n",
            "Batch 110: Loss = 1.1529998779296875, accuracy = 0.5\n",
            "Validation: Loss = 1.305099604422586, accuracy = 0.5630252100840336\n",
            "======== Epoch: 10 ========\n",
            "Batch 10: Loss = 1.3242225646972656, accuracy = 0.625\n",
            "Batch 20: Loss = 1.4212493896484375, accuracy = 0.375\n",
            "Batch 30: Loss = 1.2575149536132812, accuracy = 0.625\n",
            "Batch 40: Loss = 2.1732025146484375, accuracy = 0.375\n",
            "Batch 50: Loss = 1.101654052734375, accuracy = 0.625\n",
            "Batch 60: Loss = 0.917510986328125, accuracy = 0.75\n",
            "Batch 70: Loss = 0.4398345947265625, accuracy = 0.875\n",
            "Batch 80: Loss = 1.6782798767089844, accuracy = 0.625\n",
            "Batch 90: Loss = 0.8736610412597656, accuracy = 0.75\n",
            "Batch 100: Loss = 0.9716835021972656, accuracy = 0.5\n",
            "Batch 110: Loss = 1.164398193359375, accuracy = 0.5\n",
            "Validation: Loss = 1.3718091354035495, accuracy = 0.6302521008403361\n",
            "======== Epoch: 11 ========\n",
            "Batch 10: Loss = 1.901540756225586, accuracy = 0.375\n",
            "Batch 20: Loss = 0.98358154296875, accuracy = 0.625\n",
            "Batch 30: Loss = 0.6760177612304688, accuracy = 0.75\n",
            "Batch 40: Loss = 1.329803466796875, accuracy = 0.625\n",
            "Batch 50: Loss = 1.263671875, accuracy = 0.75\n",
            "Batch 60: Loss = 1.3163833618164062, accuracy = 0.625\n",
            "Batch 70: Loss = 1.394601821899414, accuracy = 0.5\n",
            "Batch 80: Loss = 2.094024658203125, accuracy = 0.25\n",
            "Batch 90: Loss = 1.0994491577148438, accuracy = 0.625\n",
            "Batch 100: Loss = 0.9403400421142578, accuracy = 0.625\n",
            "Batch 110: Loss = 2.033660888671875, accuracy = 0.625\n",
            "Validation: Loss = 1.283418621933251, accuracy = 0.6050420168067226\n",
            "======== Epoch: 12 ========\n",
            "Batch 10: Loss = 1.46295166015625, accuracy = 0.375\n",
            "Batch 20: Loss = 1.1761322021484375, accuracy = 0.5\n",
            "Batch 30: Loss = 0.9293632507324219, accuracy = 0.75\n",
            "Batch 40: Loss = 0.8297348022460938, accuracy = 0.625\n",
            "Batch 50: Loss = 1.1163482666015625, accuracy = 0.5\n",
            "Batch 60: Loss = 1.1280059814453125, accuracy = 0.5\n",
            "Batch 70: Loss = 0.6283187866210938, accuracy = 0.875\n",
            "Batch 80: Loss = 1.33648681640625, accuracy = 0.25\n",
            "Batch 90: Loss = 1.3905029296875, accuracy = 0.5\n",
            "Batch 100: Loss = 0.9948720932006836, accuracy = 0.75\n",
            "Batch 110: Loss = 2.0439720153808594, accuracy = 0.625\n",
            "Validation: Loss = 1.36770344617074, accuracy = 0.5546218487394958\n",
            "======== Epoch: 13 ========\n",
            "Batch 10: Loss = 1.1169681549072266, accuracy = 0.625\n",
            "Batch 20: Loss = 1.6344146728515625, accuracy = 0.5\n",
            "Batch 30: Loss = 0.9049835205078125, accuracy = 0.625\n",
            "Batch 40: Loss = 0.460113525390625, accuracy = 1.0\n",
            "Batch 50: Loss = 0.6421051025390625, accuracy = 0.625\n",
            "Batch 60: Loss = 1.47186279296875, accuracy = 0.375\n",
            "Batch 70: Loss = 0.5143442153930664, accuracy = 0.875\n",
            "Batch 80: Loss = 0.7603797912597656, accuracy = 0.75\n",
            "Batch 90: Loss = 1.9390869140625, accuracy = 0.375\n",
            "Batch 100: Loss = 1.231353759765625, accuracy = 0.5\n",
            "Batch 110: Loss = 0.75665283203125, accuracy = 0.75\n",
            "Validation: Loss = 1.3505337363795231, accuracy = 0.5966386554621849\n",
            "======== Epoch: 14 ========\n",
            "Batch 10: Loss = 1.4274826049804688, accuracy = 0.5\n",
            "Batch 20: Loss = 1.0033950805664062, accuracy = 0.375\n",
            "Batch 30: Loss = 0.9770965576171875, accuracy = 0.625\n",
            "Batch 40: Loss = 1.3533210754394531, accuracy = 0.25\n",
            "Batch 50: Loss = 1.2583694458007812, accuracy = 0.5\n",
            "Batch 60: Loss = 1.521881103515625, accuracy = 0.5\n",
            "Batch 70: Loss = 2.038604736328125, accuracy = 0.25\n",
            "Batch 80: Loss = 0.8431854248046875, accuracy = 0.75\n",
            "Batch 90: Loss = 0.7607517242431641, accuracy = 0.625\n",
            "Batch 100: Loss = 0.460906982421875, accuracy = 0.875\n",
            "Batch 110: Loss = 0.7749443054199219, accuracy = 0.75\n",
            "Validation: Loss = 1.3658321823990136, accuracy = 0.5966386554621849\n",
            "======== Epoch: 15 ========\n",
            "Batch 10: Loss = 1.071563720703125, accuracy = 0.625\n",
            "Batch 20: Loss = 1.32220458984375, accuracy = 0.25\n",
            "Batch 30: Loss = 1.75970458984375, accuracy = 0.5\n",
            "Batch 40: Loss = 0.7421722412109375, accuracy = 0.625\n",
            "Batch 50: Loss = 1.568695068359375, accuracy = 0.625\n",
            "Batch 60: Loss = 1.6092376708984375, accuracy = 0.375\n",
            "Batch 70: Loss = 0.9427947998046875, accuracy = 0.5\n",
            "Batch 80: Loss = 1.466796875, accuracy = 0.5\n",
            "Batch 90: Loss = 0.8505706787109375, accuracy = 0.75\n",
            "Batch 100: Loss = 1.6770515441894531, accuracy = 0.375\n",
            "Batch 110: Loss = 0.790008544921875, accuracy = 0.875\n",
            "Validation: Loss = 1.3505960932949133, accuracy = 0.5126050420168067\n",
            "======== Epoch: 16 ========\n",
            "Batch 10: Loss = 1.4431953430175781, accuracy = 0.5\n",
            "Batch 20: Loss = 0.7769317626953125, accuracy = 0.75\n",
            "Batch 30: Loss = 1.0667037963867188, accuracy = 0.5\n",
            "Batch 40: Loss = 1.2590899467468262, accuracy = 0.625\n",
            "Batch 50: Loss = 0.8323287963867188, accuracy = 0.5\n",
            "Batch 60: Loss = 1.8502788543701172, accuracy = 0.25\n",
            "Batch 70: Loss = 0.7899875640869141, accuracy = 0.625\n",
            "Batch 80: Loss = 1.2128067016601562, accuracy = 0.625\n",
            "Batch 90: Loss = 0.8253660202026367, accuracy = 0.625\n",
            "Batch 100: Loss = 0.3387775421142578, accuracy = 1.0\n",
            "Batch 110: Loss = 1.0201873779296875, accuracy = 0.75\n",
            "Validation: Loss = 1.1580881863309627, accuracy = 0.6470588235294118\n",
            "======== Epoch: 17 ========\n",
            "Batch 10: Loss = 0.7898063659667969, accuracy = 0.5\n",
            "Batch 20: Loss = 0.7146186828613281, accuracy = 0.875\n",
            "Batch 30: Loss = 1.299367904663086, accuracy = 0.375\n",
            "Batch 40: Loss = 1.2314224243164062, accuracy = 0.625\n",
            "Batch 50: Loss = 0.6099472045898438, accuracy = 0.875\n",
            "Batch 60: Loss = 0.5914764404296875, accuracy = 0.75\n",
            "Batch 70: Loss = 0.8182449340820312, accuracy = 0.75\n",
            "Batch 80: Loss = 1.790557861328125, accuracy = 0.375\n",
            "Batch 90: Loss = 1.0702552795410156, accuracy = 0.375\n",
            "Batch 100: Loss = 1.8414077758789062, accuracy = 0.5\n",
            "Batch 110: Loss = 0.7977657318115234, accuracy = 0.75\n",
            "Validation: Loss = 1.099190448459826, accuracy = 0.6470588235294118\n",
            "======== Epoch: 18 ========\n",
            "Batch 10: Loss = 1.0283203125, accuracy = 0.5\n",
            "Batch 20: Loss = 0.4885292053222656, accuracy = 0.875\n",
            "Batch 30: Loss = 0.8838672637939453, accuracy = 0.5\n",
            "Batch 40: Loss = 0.9337005615234375, accuracy = 0.75\n",
            "Batch 50: Loss = 1.14532470703125, accuracy = 0.625\n",
            "Batch 60: Loss = 0.86505126953125, accuracy = 0.75\n",
            "Batch 70: Loss = 1.650238037109375, accuracy = 0.5\n",
            "Batch 80: Loss = 1.2006378173828125, accuracy = 0.375\n",
            "Batch 90: Loss = 0.9215354919433594, accuracy = 0.625\n",
            "Batch 100: Loss = 1.16741943359375, accuracy = 0.625\n",
            "Batch 110: Loss = 0.8191299438476562, accuracy = 0.625\n",
            "Validation: Loss = 1.131895521230865, accuracy = 0.6386554621848739\n",
            "======== Epoch: 19 ========\n",
            "Batch 10: Loss = 0.7456197738647461, accuracy = 0.75\n",
            "Batch 20: Loss = 0.47982311248779297, accuracy = 0.875\n",
            "Batch 30: Loss = 0.79046630859375, accuracy = 0.75\n",
            "Batch 40: Loss = 0.7761116027832031, accuracy = 0.75\n",
            "Batch 50: Loss = 0.5661773681640625, accuracy = 0.75\n",
            "Batch 60: Loss = 1.0229949951171875, accuracy = 0.625\n",
            "Batch 70: Loss = 1.1637420654296875, accuracy = 0.625\n",
            "Batch 80: Loss = 1.231083869934082, accuracy = 0.75\n",
            "Batch 90: Loss = 0.7579879760742188, accuracy = 0.75\n",
            "Batch 100: Loss = 1.0260734558105469, accuracy = 0.5\n",
            "Batch 110: Loss = 0.2202911376953125, accuracy = 0.875\n",
            "Validation: Loss = 1.1333451229229308, accuracy = 0.6218487394957983\n",
            "======== Epoch: 20 ========\n",
            "Batch 10: Loss = 0.5641975402832031, accuracy = 0.875\n",
            "Batch 20: Loss = 0.8767662048339844, accuracy = 0.75\n",
            "Batch 30: Loss = 0.6727294921875, accuracy = 0.625\n",
            "Batch 40: Loss = 1.3425750732421875, accuracy = 0.5\n",
            "Batch 50: Loss = 1.388620376586914, accuracy = 0.5\n",
            "Batch 60: Loss = 1.1569976806640625, accuracy = 0.625\n",
            "Batch 70: Loss = 0.49654388427734375, accuracy = 0.875\n",
            "Batch 80: Loss = 1.8420515060424805, accuracy = 0.5\n",
            "Batch 90: Loss = 0.6419677734375, accuracy = 0.75\n",
            "Batch 100: Loss = 1.0104150772094727, accuracy = 0.75\n",
            "Batch 110: Loss = 0.48293638229370117, accuracy = 0.875\n",
            "Validation: Loss = 1.0193024727336146, accuracy = 0.6722689075630253\n",
            "======== Epoch: 21 ========\n",
            "Batch 10: Loss = 1.5549049377441406, accuracy = 0.625\n",
            "Batch 20: Loss = 0.11721038818359375, accuracy = 1.0\n",
            "Batch 30: Loss = 0.6594009399414062, accuracy = 0.875\n",
            "Batch 40: Loss = 1.1058769226074219, accuracy = 0.75\n",
            "Batch 50: Loss = 0.6042098999023438, accuracy = 0.875\n",
            "Batch 60: Loss = 0.4773216247558594, accuracy = 0.875\n",
            "Batch 70: Loss = 0.42978572845458984, accuracy = 0.875\n",
            "Batch 80: Loss = 0.8038311004638672, accuracy = 0.625\n",
            "Batch 90: Loss = 1.2597618103027344, accuracy = 0.625\n",
            "Batch 100: Loss = 0.5775489807128906, accuracy = 0.875\n",
            "Batch 110: Loss = 1.130868911743164, accuracy = 0.5\n",
            "Validation: Loss = 1.0223376625462581, accuracy = 0.6386554621848739\n",
            "======== Epoch: 22 ========\n",
            "Batch 10: Loss = 0.42371559143066406, accuracy = 1.0\n",
            "Batch 20: Loss = 0.6563377380371094, accuracy = 0.875\n",
            "Batch 30: Loss = 0.7681550979614258, accuracy = 0.5\n",
            "Batch 40: Loss = 1.4150915145874023, accuracy = 0.625\n",
            "Batch 50: Loss = 0.3663368225097656, accuracy = 0.75\n",
            "Batch 60: Loss = 1.3002300262451172, accuracy = 0.5\n",
            "Batch 70: Loss = 0.27672672271728516, accuracy = 0.875\n",
            "Batch 80: Loss = 2.13385009765625, accuracy = 0.375\n",
            "Batch 90: Loss = 0.6221542358398438, accuracy = 0.75\n",
            "Batch 100: Loss = 1.3667526245117188, accuracy = 0.375\n",
            "Batch 110: Loss = 0.8023910522460938, accuracy = 0.75\n",
            "Validation: Loss = 1.1066618509459913, accuracy = 0.6722689075630253\n",
            "======== Epoch: 23 ========\n",
            "Batch 10: Loss = 0.5358009338378906, accuracy = 0.875\n",
            "Batch 20: Loss = 0.9876747131347656, accuracy = 0.625\n",
            "Batch 30: Loss = 1.1918659210205078, accuracy = 0.5\n",
            "Batch 40: Loss = 0.6814384460449219, accuracy = 0.625\n",
            "Batch 50: Loss = 0.57049560546875, accuracy = 0.875\n",
            "Batch 60: Loss = 0.877744197845459, accuracy = 0.625\n",
            "Batch 70: Loss = 1.04437255859375, accuracy = 0.625\n",
            "Batch 80: Loss = 1.0195960998535156, accuracy = 0.625\n",
            "Batch 90: Loss = 0.7435531616210938, accuracy = 0.75\n",
            "Batch 100: Loss = 0.7726287841796875, accuracy = 0.625\n",
            "Batch 110: Loss = 0.9173049926757812, accuracy = 0.5\n",
            "Validation: Loss = 1.0046561308074415, accuracy = 0.6974789915966386\n",
            "======== Epoch: 24 ========\n",
            "Batch 10: Loss = 1.1203994750976562, accuracy = 0.5\n",
            "Batch 20: Loss = 2.067230224609375, accuracy = 0.25\n",
            "Batch 30: Loss = 0.8204383850097656, accuracy = 0.75\n",
            "Batch 40: Loss = 0.42479705810546875, accuracy = 0.875\n",
            "Batch 50: Loss = 0.8369255065917969, accuracy = 0.625\n",
            "Batch 60: Loss = 0.5167388916015625, accuracy = 0.875\n",
            "Batch 70: Loss = 0.6631546020507812, accuracy = 0.75\n",
            "Batch 80: Loss = 0.6308364868164062, accuracy = 0.625\n",
            "Batch 90: Loss = 0.5644435882568359, accuracy = 0.875\n",
            "Batch 100: Loss = 0.42243194580078125, accuracy = 0.875\n",
            "Batch 110: Loss = 0.9725799560546875, accuracy = 0.625\n",
            "Validation: Loss = 1.026001854946739, accuracy = 0.6974789915966386\n",
            "======== Epoch: 25 ========\n",
            "Batch 10: Loss = 0.9544448852539062, accuracy = 0.875\n",
            "Batch 20: Loss = 0.7512283325195312, accuracy = 0.75\n",
            "Batch 30: Loss = 0.8065376281738281, accuracy = 0.75\n",
            "Batch 40: Loss = 0.5368156433105469, accuracy = 0.75\n",
            "Batch 50: Loss = 0.6573333740234375, accuracy = 0.75\n",
            "Batch 60: Loss = 0.8814258575439453, accuracy = 0.75\n",
            "Batch 70: Loss = 1.177328109741211, accuracy = 0.75\n",
            "Batch 80: Loss = 0.9760398864746094, accuracy = 0.625\n",
            "Batch 90: Loss = 1.0403797626495361, accuracy = 0.625\n",
            "Batch 100: Loss = 0.5571632385253906, accuracy = 0.875\n",
            "Batch 110: Loss = 0.3386726379394531, accuracy = 0.875\n",
            "Validation: Loss = 1.0547386386938262, accuracy = 0.6638655462184874\n",
            "======== Epoch: 26 ========\n",
            "Batch 10: Loss = 1.0986032485961914, accuracy = 0.625\n",
            "Batch 20: Loss = 0.4471921920776367, accuracy = 0.875\n",
            "Batch 30: Loss = 0.9288346767425537, accuracy = 0.75\n",
            "Batch 40: Loss = 1.056229591369629, accuracy = 0.625\n",
            "Batch 50: Loss = 0.32737255096435547, accuracy = 0.875\n",
            "Batch 60: Loss = 0.7244873046875, accuracy = 0.75\n",
            "Batch 70: Loss = 0.4175271987915039, accuracy = 0.875\n",
            "Batch 80: Loss = 1.5036430358886719, accuracy = 0.5\n",
            "Batch 90: Loss = 0.3680896759033203, accuracy = 1.0\n",
            "Batch 100: Loss = 1.2719647884368896, accuracy = 0.625\n",
            "Batch 110: Loss = 0.3607180118560791, accuracy = 0.875\n",
            "Validation: Loss = 0.9665309755425704, accuracy = 0.6722689075630253\n",
            "======== Epoch: 27 ========\n",
            "Batch 10: Loss = 1.0051283836364746, accuracy = 0.625\n",
            "Batch 20: Loss = 0.7876839637756348, accuracy = 0.625\n",
            "Batch 30: Loss = 0.4239635467529297, accuracy = 0.75\n",
            "Batch 40: Loss = 0.9512662887573242, accuracy = 0.75\n",
            "Batch 50: Loss = 0.8011932373046875, accuracy = 0.75\n",
            "Batch 60: Loss = 0.8835563659667969, accuracy = 0.875\n",
            "Batch 70: Loss = 0.39883995056152344, accuracy = 0.875\n",
            "Batch 80: Loss = 1.2357978820800781, accuracy = 0.625\n",
            "Batch 90: Loss = 1.4070816040039062, accuracy = 0.5\n",
            "Batch 100: Loss = 0.19864654541015625, accuracy = 1.0\n",
            "Batch 110: Loss = 0.7400321960449219, accuracy = 0.875\n",
            "Validation: Loss = 1.1216338726512172, accuracy = 0.6470588235294118\n",
            "======== Epoch: 28 ========\n",
            "Batch 10: Loss = 0.47930431365966797, accuracy = 0.75\n",
            "Batch 20: Loss = 0.4019355773925781, accuracy = 0.875\n",
            "Batch 30: Loss = 1.0231547355651855, accuracy = 0.625\n",
            "Batch 40: Loss = 0.6102828979492188, accuracy = 0.875\n",
            "Batch 50: Loss = 0.8572025299072266, accuracy = 0.5\n",
            "Batch 60: Loss = 1.2087974548339844, accuracy = 0.625\n",
            "Batch 70: Loss = 0.7145614624023438, accuracy = 0.625\n",
            "Batch 80: Loss = 0.5141658782958984, accuracy = 0.75\n",
            "Batch 90: Loss = 1.2625274658203125, accuracy = 0.625\n",
            "Batch 100: Loss = 0.8206701278686523, accuracy = 0.875\n",
            "Batch 110: Loss = 0.5538959503173828, accuracy = 0.75\n",
            "Validation: Loss = 1.1865704603362501, accuracy = 0.5966386554621849\n",
            "======== Epoch: 29 ========\n",
            "Batch 10: Loss = 0.8804283142089844, accuracy = 0.625\n",
            "Batch 20: Loss = 0.7384700775146484, accuracy = 0.625\n",
            "Batch 30: Loss = 0.7235031127929688, accuracy = 0.75\n",
            "Batch 40: Loss = 0.5706119537353516, accuracy = 0.75\n",
            "Batch 50: Loss = 0.9879302978515625, accuracy = 0.625\n",
            "Batch 60: Loss = 0.2259502410888672, accuracy = 1.0\n",
            "Batch 70: Loss = 0.8955364227294922, accuracy = 0.75\n",
            "Batch 80: Loss = 0.3139219284057617, accuracy = 0.875\n",
            "Batch 90: Loss = 0.66552734375, accuracy = 0.75\n",
            "Batch 100: Loss = 0.825286865234375, accuracy = 0.75\n",
            "Batch 110: Loss = 0.6425905227661133, accuracy = 0.625\n",
            "Validation: Loss = 1.0547780572322376, accuracy = 0.6134453781512605\n",
            "======== Epoch: 30 ========\n",
            "Batch 10: Loss = 0.6671333312988281, accuracy = 0.75\n",
            "Batch 20: Loss = 1.2733240127563477, accuracy = 0.625\n",
            "Batch 30: Loss = 0.3590888977050781, accuracy = 0.875\n",
            "Batch 40: Loss = 0.37467479705810547, accuracy = 0.875\n",
            "Batch 50: Loss = 0.8642082214355469, accuracy = 0.875\n",
            "Batch 60: Loss = 0.7627677917480469, accuracy = 0.75\n",
            "Batch 70: Loss = 0.7271480560302734, accuracy = 0.75\n",
            "Batch 80: Loss = 0.3493003845214844, accuracy = 0.875\n",
            "Batch 90: Loss = 0.7626838684082031, accuracy = 0.625\n",
            "Batch 100: Loss = 0.33569955825805664, accuracy = 1.0\n",
            "Batch 110: Loss = 0.5933933258056641, accuracy = 0.875\n",
            "Validation: Loss = 1.0085351299821286, accuracy = 0.6722689075630253\n",
            "======== Epoch: 31 ========\n",
            "Batch 10: Loss = 0.16378211975097656, accuracy = 1.0\n",
            "Batch 20: Loss = 1.003453254699707, accuracy = 0.5\n",
            "Batch 30: Loss = 0.32979393005371094, accuracy = 1.0\n",
            "Batch 40: Loss = 0.8216190338134766, accuracy = 0.75\n",
            "Batch 50: Loss = 0.468597412109375, accuracy = 0.875\n",
            "Batch 60: Loss = 1.7565383911132812, accuracy = 0.625\n",
            "Batch 70: Loss = 1.3316459655761719, accuracy = 0.25\n",
            "Batch 80: Loss = 0.8342456817626953, accuracy = 0.75\n",
            "Batch 90: Loss = 0.7712974548339844, accuracy = 0.75\n",
            "Batch 100: Loss = 0.3374505043029785, accuracy = 0.875\n",
            "Batch 110: Loss = 0.3932342529296875, accuracy = 0.875\n",
            "Validation: Loss = 0.9534953309778582, accuracy = 0.7142857142857143\n",
            "======== Epoch: 32 ========\n",
            "Batch 10: Loss = 0.6407260894775391, accuracy = 0.75\n",
            "Batch 20: Loss = 0.30614280700683594, accuracy = 0.875\n",
            "Batch 30: Loss = 0.24030494689941406, accuracy = 1.0\n",
            "Batch 40: Loss = 0.28606414794921875, accuracy = 0.875\n",
            "Batch 50: Loss = 0.6355667114257812, accuracy = 0.75\n",
            "Batch 60: Loss = 0.9536628723144531, accuracy = 0.75\n",
            "Batch 70: Loss = 1.2535781860351562, accuracy = 0.5\n",
            "Batch 80: Loss = 1.4610943794250488, accuracy = 0.625\n",
            "Batch 90: Loss = 0.36550283432006836, accuracy = 1.0\n",
            "Batch 100: Loss = 1.1450023651123047, accuracy = 0.5\n",
            "Batch 110: Loss = 0.8048012256622314, accuracy = 0.75\n",
            "Validation: Loss = 0.9575544616632294, accuracy = 0.6974789915966386\n",
            "======== Epoch: 33 ========\n",
            "Batch 10: Loss = 0.8155517578125, accuracy = 0.75\n",
            "Batch 20: Loss = 0.7957639694213867, accuracy = 0.75\n",
            "Batch 30: Loss = 1.0209770202636719, accuracy = 0.5\n",
            "Batch 40: Loss = 0.30989646911621094, accuracy = 1.0\n",
            "Batch 50: Loss = 0.4601931571960449, accuracy = 0.75\n",
            "Batch 60: Loss = 0.39902687072753906, accuracy = 0.875\n",
            "Batch 70: Loss = 0.5268821716308594, accuracy = 0.875\n",
            "Batch 80: Loss = 0.28955310583114624, accuracy = 1.0\n",
            "Batch 90: Loss = 0.6599551439285278, accuracy = 0.75\n",
            "Batch 100: Loss = 1.0171847343444824, accuracy = 0.625\n",
            "Batch 110: Loss = 0.4304389953613281, accuracy = 0.875\n",
            "Validation: Loss = 0.9419714777093184, accuracy = 0.7226890756302521\n",
            "======== Epoch: 34 ========\n",
            "Batch 10: Loss = 0.5952644348144531, accuracy = 0.625\n",
            "Batch 20: Loss = 0.4583439826965332, accuracy = 0.75\n",
            "Batch 30: Loss = 0.9157941341400146, accuracy = 0.625\n",
            "Batch 40: Loss = 0.23111343383789062, accuracy = 1.0\n",
            "Batch 50: Loss = 0.5579643249511719, accuracy = 0.75\n",
            "Batch 60: Loss = 0.3030986785888672, accuracy = 0.875\n",
            "Batch 70: Loss = 0.5773205757141113, accuracy = 0.875\n",
            "Batch 80: Loss = 0.5802364349365234, accuracy = 0.875\n",
            "Batch 90: Loss = 0.9265937805175781, accuracy = 0.625\n",
            "Batch 100: Loss = 0.3641357421875, accuracy = 0.875\n",
            "Batch 110: Loss = 0.37837648391723633, accuracy = 0.75\n",
            "Validation: Loss = 1.0035484799167567, accuracy = 0.680672268907563\n",
            "======== Epoch: 35 ========\n",
            "Batch 10: Loss = 0.2702903747558594, accuracy = 1.0\n",
            "Batch 20: Loss = 0.12933599948883057, accuracy = 1.0\n",
            "Batch 30: Loss = 0.9807300567626953, accuracy = 0.75\n",
            "Batch 40: Loss = 0.5098230838775635, accuracy = 0.875\n",
            "Batch 50: Loss = 0.11615943908691406, accuracy = 1.0\n",
            "Batch 60: Loss = 1.054368019104004, accuracy = 0.875\n",
            "Batch 70: Loss = 0.44035959243774414, accuracy = 0.875\n",
            "Batch 80: Loss = 0.3654212951660156, accuracy = 1.0\n",
            "Batch 90: Loss = 0.9224147796630859, accuracy = 0.75\n",
            "Batch 100: Loss = 0.5894699096679688, accuracy = 0.875\n",
            "Batch 110: Loss = 0.6495704650878906, accuracy = 0.625\n",
            "Validation: Loss = 1.0306094905786347, accuracy = 0.6890756302521008\n",
            "======== Epoch: 36 ========\n",
            "Batch 10: Loss = 0.37277746200561523, accuracy = 0.875\n",
            "Batch 20: Loss = 0.675537109375, accuracy = 0.75\n",
            "Batch 30: Loss = 0.6376571655273438, accuracy = 0.75\n",
            "Batch 40: Loss = 0.423309326171875, accuracy = 0.75\n",
            "Batch 50: Loss = 0.36824798583984375, accuracy = 0.875\n",
            "Batch 60: Loss = 0.6413426399230957, accuracy = 0.75\n",
            "Batch 70: Loss = 0.42455101013183594, accuracy = 0.875\n",
            "Batch 80: Loss = 0.7061712741851807, accuracy = 0.75\n",
            "Batch 90: Loss = 0.35724639892578125, accuracy = 0.875\n",
            "Batch 100: Loss = 0.5218048095703125, accuracy = 0.875\n",
            "Batch 110: Loss = 0.9725570678710938, accuracy = 0.875\n",
            "Validation: Loss = 1.0081927441714102, accuracy = 0.6722689075630253\n",
            "======== Epoch: 37 ========\n",
            "Batch 10: Loss = 0.4270949363708496, accuracy = 0.875\n",
            "Batch 20: Loss = 0.23942601680755615, accuracy = 0.875\n",
            "Batch 30: Loss = 0.7256016731262207, accuracy = 0.75\n",
            "Batch 40: Loss = 0.6686649322509766, accuracy = 0.625\n",
            "Batch 50: Loss = 0.17543649673461914, accuracy = 1.0\n",
            "Batch 60: Loss = 0.21731281280517578, accuracy = 1.0\n",
            "Batch 70: Loss = 0.7398433685302734, accuracy = 0.875\n",
            "Batch 80: Loss = 0.3826751708984375, accuracy = 0.875\n",
            "Batch 90: Loss = 0.22861969470977783, accuracy = 0.875\n",
            "Batch 100: Loss = 0.4231071472167969, accuracy = 0.875\n",
            "Batch 110: Loss = 0.37221717834472656, accuracy = 0.875\n",
            "Validation: Loss = 1.0480425023196036, accuracy = 0.6302521008403361\n",
            "======== Epoch: 38 ========\n",
            "Batch 10: Loss = 0.5816135406494141, accuracy = 0.75\n",
            "Batch 20: Loss = 0.3311758041381836, accuracy = 0.875\n",
            "Batch 30: Loss = 0.4140024185180664, accuracy = 0.75\n",
            "Batch 40: Loss = 0.4929715394973755, accuracy = 0.875\n",
            "Batch 50: Loss = 0.24985313415527344, accuracy = 0.875\n",
            "Batch 60: Loss = 0.7826499938964844, accuracy = 0.75\n",
            "Batch 70: Loss = 0.31396484375, accuracy = 0.875\n",
            "Batch 80: Loss = 0.13974905014038086, accuracy = 1.0\n",
            "Batch 90: Loss = 0.23144769668579102, accuracy = 1.0\n",
            "Batch 100: Loss = 0.7127094268798828, accuracy = 0.75\n",
            "Batch 110: Loss = 0.27347588539123535, accuracy = 0.875\n",
            "Validation: Loss = 0.9456333444829572, accuracy = 0.7142857142857143\n",
            "======== Epoch: 39 ========\n",
            "Batch 10: Loss = 1.1358442306518555, accuracy = 0.5\n",
            "Batch 20: Loss = 0.14963245391845703, accuracy = 1.0\n",
            "Batch 30: Loss = 0.5058226585388184, accuracy = 0.875\n",
            "Batch 40: Loss = 0.46579742431640625, accuracy = 0.875\n",
            "Batch 50: Loss = 0.11726880073547363, accuracy = 1.0\n",
            "Batch 60: Loss = 0.5399341583251953, accuracy = 0.75\n",
            "Batch 70: Loss = 0.1996746063232422, accuracy = 1.0\n",
            "Batch 80: Loss = 0.31843090057373047, accuracy = 0.875\n",
            "Batch 90: Loss = 0.14298057556152344, accuracy = 1.0\n",
            "Batch 100: Loss = 0.6471114158630371, accuracy = 0.75\n",
            "Batch 110: Loss = 0.3964405059814453, accuracy = 0.875\n",
            "Validation: Loss = 0.921723395063166, accuracy = 0.7394957983193278\n",
            "======== Epoch: 40 ========\n",
            "Batch 10: Loss = 0.33714914321899414, accuracy = 0.875\n",
            "Batch 20: Loss = 0.3756399154663086, accuracy = 0.875\n",
            "Batch 30: Loss = 0.6433935165405273, accuracy = 0.75\n",
            "Batch 40: Loss = 0.33518218994140625, accuracy = 0.875\n",
            "Batch 50: Loss = 0.6477165222167969, accuracy = 0.75\n",
            "Batch 60: Loss = 0.656624436378479, accuracy = 0.75\n",
            "Batch 70: Loss = 0.6658668518066406, accuracy = 0.625\n",
            "Batch 80: Loss = 0.2723836898803711, accuracy = 0.875\n",
            "Batch 90: Loss = 0.6773128509521484, accuracy = 0.875\n",
            "Batch 100: Loss = 0.8635096549987793, accuracy = 0.75\n",
            "Batch 110: Loss = 0.4716014862060547, accuracy = 0.75\n",
            "Validation: Loss = 0.9510083742309035, accuracy = 0.6890756302521008\n",
            "======== Epoch: 41 ========\n",
            "Batch 10: Loss = 0.20336580276489258, accuracy = 0.875\n",
            "Batch 20: Loss = 0.34037017822265625, accuracy = 0.875\n",
            "Batch 30: Loss = 0.5727505683898926, accuracy = 0.875\n",
            "Batch 40: Loss = 0.16001129150390625, accuracy = 1.0\n",
            "Batch 50: Loss = 0.10230255126953125, accuracy = 1.0\n",
            "Batch 60: Loss = 0.11030292510986328, accuracy = 1.0\n",
            "Batch 70: Loss = 0.5256443023681641, accuracy = 0.625\n",
            "Batch 80: Loss = 1.053102970123291, accuracy = 0.625\n",
            "Batch 90: Loss = 0.25662916898727417, accuracy = 0.875\n",
            "Batch 100: Loss = 0.39738917350769043, accuracy = 0.875\n",
            "Batch 110: Loss = 0.8428658246994019, accuracy = 0.75\n",
            "Validation: Loss = 0.9838319870463589, accuracy = 0.6890756302521008\n",
            "======== Epoch: 42 ========\n",
            "Batch 10: Loss = 1.1279089450836182, accuracy = 0.625\n",
            "Batch 20: Loss = 1.2413902282714844, accuracy = 0.625\n",
            "Batch 30: Loss = 0.22356414794921875, accuracy = 1.0\n",
            "Batch 40: Loss = 0.2779693603515625, accuracy = 0.875\n",
            "Batch 50: Loss = 0.9567798376083374, accuracy = 0.75\n",
            "Batch 60: Loss = 0.5386619567871094, accuracy = 0.75\n",
            "Batch 70: Loss = 0.8070926666259766, accuracy = 0.75\n",
            "Batch 80: Loss = 0.37729716300964355, accuracy = 0.875\n",
            "Batch 90: Loss = 0.25036299228668213, accuracy = 0.875\n",
            "Batch 100: Loss = 0.3708977699279785, accuracy = 0.75\n",
            "Batch 110: Loss = 0.9982905387878418, accuracy = 0.625\n",
            "Validation: Loss = 1.0141846422563519, accuracy = 0.6890756302521008\n",
            "======== Epoch: 43 ========\n",
            "Batch 10: Loss = 0.480471134185791, accuracy = 0.75\n",
            "Batch 20: Loss = 0.48154497146606445, accuracy = 0.75\n",
            "Batch 30: Loss = 0.3260841369628906, accuracy = 0.875\n",
            "Batch 40: Loss = 0.35881996154785156, accuracy = 0.875\n",
            "Batch 50: Loss = 0.5378203392028809, accuracy = 0.625\n",
            "Batch 60: Loss = 0.6016473770141602, accuracy = 0.75\n",
            "Batch 70: Loss = 0.5420502424240112, accuracy = 0.875\n",
            "Batch 80: Loss = 0.5727686882019043, accuracy = 0.75\n",
            "Batch 90: Loss = 0.7690830230712891, accuracy = 0.75\n",
            "Batch 100: Loss = 0.691340446472168, accuracy = 0.75\n",
            "Batch 110: Loss = 0.9450840950012207, accuracy = 0.75\n",
            "Validation: Loss = 0.9328433881726181, accuracy = 0.6974789915966386\n",
            "======== Epoch: 44 ========\n",
            "Batch 10: Loss = 1.5044574737548828, accuracy = 0.375\n",
            "Batch 20: Loss = 0.3409007787704468, accuracy = 0.875\n",
            "Batch 30: Loss = 0.13896751403808594, accuracy = 1.0\n",
            "Batch 40: Loss = 0.25370216369628906, accuracy = 1.0\n",
            "Batch 50: Loss = 0.26483702659606934, accuracy = 1.0\n",
            "Batch 60: Loss = 0.4276294708251953, accuracy = 0.875\n",
            "Batch 70: Loss = 0.2564883232116699, accuracy = 0.875\n",
            "Batch 80: Loss = 0.6773796081542969, accuracy = 0.625\n",
            "Batch 90: Loss = 0.6681127548217773, accuracy = 0.75\n",
            "Batch 100: Loss = 0.12831735610961914, accuracy = 1.0\n",
            "Batch 110: Loss = 0.40866851806640625, accuracy = 0.875\n",
            "Validation: Loss = 0.9445421946676154, accuracy = 0.7226890756302521\n",
            "======== Epoch: 45 ========\n",
            "Batch 10: Loss = 0.5395584106445312, accuracy = 0.875\n",
            "Batch 20: Loss = 0.3003082275390625, accuracy = 1.0\n",
            "Batch 30: Loss = 0.39156341552734375, accuracy = 0.875\n",
            "Batch 40: Loss = 0.9066991806030273, accuracy = 0.625\n",
            "Batch 50: Loss = 0.6721305847167969, accuracy = 0.875\n",
            "Batch 60: Loss = 0.2968912124633789, accuracy = 0.875\n",
            "Batch 70: Loss = 0.24150323867797852, accuracy = 1.0\n",
            "Batch 80: Loss = 0.5786929130554199, accuracy = 0.75\n",
            "Batch 90: Loss = 1.0882320404052734, accuracy = 0.625\n",
            "Batch 100: Loss = 0.4790065288543701, accuracy = 0.625\n",
            "Batch 110: Loss = 0.5443747043609619, accuracy = 0.875\n",
            "Validation: Loss = 0.9059199910414847, accuracy = 0.7478991596638656\n",
            "======== Epoch: 46 ========\n",
            "Batch 10: Loss = 0.401214599609375, accuracy = 0.875\n",
            "Batch 20: Loss = 0.7183630466461182, accuracy = 0.75\n",
            "Batch 30: Loss = 0.2418651580810547, accuracy = 1.0\n",
            "Batch 40: Loss = 0.1662306785583496, accuracy = 1.0\n",
            "Batch 50: Loss = 0.6753463745117188, accuracy = 0.625\n",
            "Batch 60: Loss = 0.29638195037841797, accuracy = 0.875\n",
            "Batch 70: Loss = 0.12151145935058594, accuracy = 1.0\n",
            "Batch 80: Loss = 0.8992966413497925, accuracy = 0.75\n",
            "Batch 90: Loss = 0.8896241188049316, accuracy = 0.75\n",
            "Batch 100: Loss = 1.0315322875976562, accuracy = 0.625\n",
            "Batch 110: Loss = 0.6088370084762573, accuracy = 0.75\n",
            "Validation: Loss = 0.94012535245795, accuracy = 0.6638655462184874\n",
            "======== Epoch: 47 ========\n",
            "Batch 10: Loss = 0.15880489349365234, accuracy = 0.875\n",
            "Batch 20: Loss = 0.3206944465637207, accuracy = 0.875\n",
            "Batch 30: Loss = 0.22806167602539062, accuracy = 1.0\n",
            "Batch 40: Loss = 0.2880210876464844, accuracy = 1.0\n",
            "Batch 50: Loss = 0.08332061767578125, accuracy = 1.0\n",
            "Batch 60: Loss = 0.07850837707519531, accuracy = 1.0\n",
            "Batch 70: Loss = 0.5661735534667969, accuracy = 0.875\n",
            "Batch 80: Loss = 1.0023612976074219, accuracy = 0.75\n",
            "Batch 90: Loss = 0.5700030326843262, accuracy = 0.875\n",
            "Batch 100: Loss = 0.2211465835571289, accuracy = 1.0\n",
            "Batch 110: Loss = 0.25824809074401855, accuracy = 0.875\n",
            "Validation: Loss = 0.9746923153860527, accuracy = 0.6890756302521008\n",
            "======== Epoch: 48 ========\n",
            "Batch 10: Loss = 0.4243793487548828, accuracy = 0.75\n",
            "Batch 20: Loss = 0.459888219833374, accuracy = 0.75\n",
            "Batch 30: Loss = 0.2918766736984253, accuracy = 0.875\n",
            "Batch 40: Loss = 0.3644590377807617, accuracy = 0.75\n",
            "Batch 50: Loss = 0.5303137302398682, accuracy = 0.625\n",
            "Batch 60: Loss = 0.21937674283981323, accuracy = 0.875\n",
            "Batch 70: Loss = 0.1760406494140625, accuracy = 0.875\n",
            "Batch 80: Loss = 0.5004844665527344, accuracy = 0.875\n",
            "Batch 90: Loss = 0.48595333099365234, accuracy = 0.875\n",
            "Batch 100: Loss = 0.6654777526855469, accuracy = 0.875\n",
            "Batch 110: Loss = 0.4425086975097656, accuracy = 0.75\n",
            "Validation: Loss = 0.9374417756733141, accuracy = 0.7058823529411765\n",
            "======== Epoch: 49 ========\n",
            "Batch 10: Loss = 0.2934713363647461, accuracy = 0.875\n",
            "Batch 20: Loss = 0.16824409365653992, accuracy = 0.875\n",
            "Batch 30: Loss = 0.3276205062866211, accuracy = 0.75\n",
            "Batch 40: Loss = 0.06335830688476562, accuracy = 1.0\n",
            "Batch 50: Loss = 0.36936283111572266, accuracy = 0.875\n",
            "Batch 60: Loss = 0.7628087997436523, accuracy = 0.625\n",
            "Batch 70: Loss = 0.3596687316894531, accuracy = 0.75\n",
            "Batch 80: Loss = 0.2871890068054199, accuracy = 0.875\n",
            "Batch 90: Loss = 0.7795026302337646, accuracy = 0.625\n",
            "Batch 100: Loss = 0.3895454406738281, accuracy = 0.875\n",
            "Batch 110: Loss = 0.25348758697509766, accuracy = 0.875\n",
            "Validation: Loss = 0.9379372429429439, accuracy = 0.7142857142857143\n",
            "======== Epoch: 50 ========\n",
            "Batch 10: Loss = 0.33034002780914307, accuracy = 0.875\n",
            "Batch 20: Loss = 1.0198440551757812, accuracy = 0.5\n",
            "Batch 30: Loss = 0.6942839622497559, accuracy = 0.75\n",
            "Batch 40: Loss = 0.24041271209716797, accuracy = 1.0\n",
            "Batch 50: Loss = 0.1670074462890625, accuracy = 0.875\n",
            "Batch 60: Loss = 0.73150634765625, accuracy = 0.625\n",
            "Batch 70: Loss = 0.5516433715820312, accuracy = 0.875\n",
            "Batch 80: Loss = 0.2647361755371094, accuracy = 1.0\n",
            "Batch 90: Loss = 1.0102593898773193, accuracy = 0.625\n",
            "Batch 100: Loss = 0.4149678945541382, accuracy = 0.875\n",
            "Batch 110: Loss = 0.18508633971214294, accuracy = 1.0\n",
            "Validation: Loss = 0.9522324361299214, accuracy = 0.7226890756302521\n",
            "======== Epoch: 51 ========\n",
            "Batch 10: Loss = 0.16319000720977783, accuracy = 1.0\n",
            "Batch 20: Loss = 1.6946334838867188, accuracy = 0.5\n",
            "Batch 30: Loss = 0.10706138610839844, accuracy = 1.0\n",
            "Batch 40: Loss = 1.2419815063476562, accuracy = 0.75\n",
            "Batch 50: Loss = 0.22199440002441406, accuracy = 1.0\n",
            "Batch 60: Loss = 0.09902238845825195, accuracy = 1.0\n",
            "Batch 70: Loss = 0.43314552307128906, accuracy = 0.875\n",
            "Batch 80: Loss = 0.4781012535095215, accuracy = 0.75\n",
            "Batch 90: Loss = 0.4157109260559082, accuracy = 0.75\n",
            "Batch 100: Loss = 0.1987590789794922, accuracy = 1.0\n",
            "Batch 110: Loss = 0.20542526245117188, accuracy = 0.875\n",
            "Validation: Loss = 0.9231215694494415, accuracy = 0.6974789915966386\n",
            "======== Epoch: 52 ========\n",
            "Batch 10: Loss = 0.4573245048522949, accuracy = 0.875\n",
            "Batch 20: Loss = 0.3152437210083008, accuracy = 0.75\n",
            "Batch 30: Loss = 0.1796189546585083, accuracy = 1.0\n",
            "Batch 40: Loss = 0.38264894485473633, accuracy = 0.875\n",
            "Batch 50: Loss = 0.8245325088500977, accuracy = 0.625\n",
            "Batch 60: Loss = 0.6830620765686035, accuracy = 0.625\n",
            "Batch 70: Loss = 0.30346250534057617, accuracy = 0.875\n",
            "Batch 80: Loss = 0.43826842308044434, accuracy = 0.75\n",
            "Batch 90: Loss = 0.16583013534545898, accuracy = 1.0\n",
            "Batch 100: Loss = 0.3472461700439453, accuracy = 0.875\n",
            "Batch 110: Loss = 0.30795955657958984, accuracy = 0.875\n",
            "Validation: Loss = 0.9540994543778268, accuracy = 0.6974789915966386\n",
            "======== Epoch: 53 ========\n",
            "Batch 10: Loss = 0.4160041809082031, accuracy = 0.75\n",
            "Batch 20: Loss = 0.4078254699707031, accuracy = 0.75\n",
            "Batch 30: Loss = 0.26355743408203125, accuracy = 0.75\n",
            "Batch 40: Loss = 0.9320411682128906, accuracy = 0.5\n",
            "Batch 50: Loss = 0.3182497024536133, accuracy = 0.875\n",
            "Batch 60: Loss = 0.5376691818237305, accuracy = 0.75\n",
            "Batch 70: Loss = 0.14511537551879883, accuracy = 1.0\n",
            "Batch 80: Loss = 0.4206252098083496, accuracy = 0.875\n",
            "Batch 90: Loss = 0.5460247993469238, accuracy = 0.75\n",
            "Batch 100: Loss = 0.11284160614013672, accuracy = 1.0\n",
            "Batch 110: Loss = 0.3388357162475586, accuracy = 0.875\n",
            "Validation: Loss = 0.9304839058926231, accuracy = 0.7058823529411765\n",
            "======== Epoch: 54 ========\n",
            "Batch 10: Loss = 0.11116790771484375, accuracy = 1.0\n",
            "Batch 20: Loss = 1.1912002563476562, accuracy = 0.625\n",
            "Batch 30: Loss = 0.18667268753051758, accuracy = 1.0\n",
            "Batch 40: Loss = 0.3940455913543701, accuracy = 0.875\n",
            "Batch 50: Loss = 0.4842109680175781, accuracy = 0.875\n",
            "Batch 60: Loss = 0.1289691925048828, accuracy = 1.0\n",
            "Batch 70: Loss = 0.20001602172851562, accuracy = 1.0\n",
            "Batch 80: Loss = 0.542773962020874, accuracy = 0.875\n",
            "Batch 90: Loss = 0.5584678649902344, accuracy = 0.75\n",
            "Batch 100: Loss = 0.055226802825927734, accuracy = 1.0\n",
            "Batch 110: Loss = 0.8446221351623535, accuracy = 0.75\n",
            "Validation: Loss = 0.9177442308057818, accuracy = 0.7142857142857143\n",
            "======== Epoch: 55 ========\n",
            "Batch 10: Loss = 0.18019819259643555, accuracy = 1.0\n",
            "Batch 20: Loss = 0.48184967041015625, accuracy = 1.0\n",
            "Batch 30: Loss = 0.2430553436279297, accuracy = 1.0\n",
            "Batch 40: Loss = 0.07962512969970703, accuracy = 1.0\n",
            "Batch 50: Loss = 0.3130483627319336, accuracy = 0.875\n",
            "Batch 60: Loss = 0.18265438079833984, accuracy = 1.0\n",
            "Batch 70: Loss = 0.3125741481781006, accuracy = 1.0\n",
            "Batch 80: Loss = 0.28648078441619873, accuracy = 0.875\n",
            "Batch 90: Loss = 0.13024282455444336, accuracy = 1.0\n",
            "Batch 100: Loss = 0.7750864028930664, accuracy = 0.75\n",
            "Batch 110: Loss = 0.3534064292907715, accuracy = 0.875\n",
            "Validation: Loss = 0.9293861849266186, accuracy = 0.7058823529411765\n",
            "======== Epoch: 56 ========\n",
            "Batch 10: Loss = 0.10293459892272949, accuracy = 1.0\n",
            "Batch 20: Loss = 0.553858757019043, accuracy = 0.75\n",
            "Batch 30: Loss = 0.3540160655975342, accuracy = 1.0\n",
            "Batch 40: Loss = 0.30060243606567383, accuracy = 0.875\n",
            "Batch 50: Loss = 0.10574913024902344, accuracy = 1.0\n",
            "Batch 60: Loss = 0.9228286743164062, accuracy = 0.625\n",
            "Batch 70: Loss = 0.22595548629760742, accuracy = 1.0\n",
            "Batch 80: Loss = 0.10067510604858398, accuracy = 1.0\n",
            "Batch 90: Loss = 0.07494306564331055, accuracy = 1.0\n",
            "Batch 100: Loss = 0.18593943119049072, accuracy = 1.0\n",
            "Batch 110: Loss = 0.5119190216064453, accuracy = 0.875\n",
            "Validation: Loss = 0.9044790560739082, accuracy = 0.7142857142857143\n",
            "======== Epoch: 57 ========\n",
            "Batch 10: Loss = 0.5113461017608643, accuracy = 0.75\n",
            "Batch 20: Loss = 0.3043975830078125, accuracy = 1.0\n",
            "Batch 30: Loss = 0.8690876960754395, accuracy = 0.625\n",
            "Batch 40: Loss = 0.11516690254211426, accuracy = 1.0\n",
            "Batch 50: Loss = 0.6336371898651123, accuracy = 0.75\n",
            "Batch 60: Loss = 1.3715665340423584, accuracy = 0.75\n",
            "Batch 70: Loss = 0.22954082489013672, accuracy = 1.0\n",
            "Batch 80: Loss = 0.5234560966491699, accuracy = 0.625\n",
            "Batch 90: Loss = 0.210113525390625, accuracy = 0.875\n",
            "Batch 100: Loss = 0.6722421646118164, accuracy = 0.75\n",
            "Batch 110: Loss = 0.8193726539611816, accuracy = 0.875\n",
            "Validation: Loss = 0.9112955059921533, accuracy = 0.7058823529411765\n",
            "======== Epoch: 58 ========\n",
            "Batch 10: Loss = 0.40463733673095703, accuracy = 0.875\n",
            "Batch 20: Loss = 0.1810370683670044, accuracy = 1.0\n",
            "Batch 30: Loss = 0.9075331687927246, accuracy = 0.75\n",
            "Batch 40: Loss = 0.5776996612548828, accuracy = 0.75\n",
            "Batch 50: Loss = 0.1745615005493164, accuracy = 1.0\n",
            "Batch 60: Loss = 0.6345791816711426, accuracy = 0.75\n",
            "Batch 70: Loss = 0.14345359802246094, accuracy = 0.875\n",
            "Batch 80: Loss = 0.25903916358947754, accuracy = 0.875\n",
            "Batch 90: Loss = 0.4665260314941406, accuracy = 0.875\n",
            "Batch 100: Loss = 0.4150547981262207, accuracy = 0.875\n",
            "Batch 110: Loss = 0.48979759216308594, accuracy = 0.75\n",
            "Validation: Loss = 0.8940084566149795, accuracy = 0.7058823529411765\n",
            "======== Epoch: 59 ========\n",
            "Batch 10: Loss = 0.3588341474533081, accuracy = 0.875\n",
            "Batch 20: Loss = 0.145033597946167, accuracy = 1.0\n",
            "Batch 30: Loss = 0.33323192596435547, accuracy = 0.875\n",
            "Batch 40: Loss = 0.5561294555664062, accuracy = 0.75\n",
            "Batch 50: Loss = 0.13866662979125977, accuracy = 1.0\n",
            "Batch 60: Loss = 0.4588794708251953, accuracy = 0.75\n",
            "Batch 70: Loss = 0.6522979736328125, accuracy = 0.75\n",
            "Batch 80: Loss = 0.3682723045349121, accuracy = 0.875\n",
            "Batch 90: Loss = 0.33121323585510254, accuracy = 0.875\n",
            "Batch 100: Loss = 0.2603425979614258, accuracy = 0.875\n",
            "Batch 110: Loss = 0.07837820053100586, accuracy = 1.0\n",
            "Validation: Loss = 0.8916333056332773, accuracy = 0.7226890756302521\n",
            "======== Epoch: 60 ========\n",
            "Batch 10: Loss = 0.6354150772094727, accuracy = 0.875\n",
            "Batch 20: Loss = 0.10052776336669922, accuracy = 1.0\n",
            "Batch 30: Loss = 0.40053606033325195, accuracy = 0.75\n",
            "Batch 40: Loss = 0.4574604034423828, accuracy = 0.625\n",
            "Batch 50: Loss = 0.5417842864990234, accuracy = 0.875\n",
            "Batch 60: Loss = 0.6074094772338867, accuracy = 0.75\n",
            "Batch 70: Loss = 0.6694733500480652, accuracy = 0.75\n",
            "Batch 80: Loss = 0.45819091796875, accuracy = 0.875\n",
            "Batch 90: Loss = 0.06486225128173828, accuracy = 1.0\n",
            "Batch 100: Loss = 0.29049062728881836, accuracy = 0.875\n",
            "Batch 110: Loss = 0.10062026977539062, accuracy = 1.0\n",
            "Validation: Loss = 0.9035549791235673, accuracy = 0.7142857142857143\n",
            "======== Epoch: 61 ========\n",
            "Batch 10: Loss = 0.3924884796142578, accuracy = 0.875\n",
            "Batch 20: Loss = 0.2448134422302246, accuracy = 1.0\n",
            "Batch 30: Loss = 0.7355556488037109, accuracy = 0.75\n",
            "Batch 40: Loss = 0.28415870666503906, accuracy = 1.0\n",
            "Batch 50: Loss = 0.34906959533691406, accuracy = 0.875\n",
            "Batch 60: Loss = 0.3447265625, accuracy = 0.875\n",
            "Batch 70: Loss = 0.6420650482177734, accuracy = 0.75\n",
            "Batch 80: Loss = 0.6687586307525635, accuracy = 0.875\n",
            "Batch 90: Loss = 0.19805610179901123, accuracy = 1.0\n",
            "Batch 100: Loss = 0.3784027099609375, accuracy = 0.75\n",
            "Batch 110: Loss = 0.35291945934295654, accuracy = 0.875\n",
            "Validation: Loss = 0.8934442704184014, accuracy = 0.7058823529411765\n",
            "======== Epoch: 62 ========\n",
            "Batch 10: Loss = 0.566044807434082, accuracy = 0.875\n",
            "Batch 20: Loss = 0.22043228149414062, accuracy = 0.875\n",
            "Batch 30: Loss = 0.6795902252197266, accuracy = 0.875\n",
            "Batch 40: Loss = 0.5104732513427734, accuracy = 0.875\n",
            "Batch 50: Loss = 0.111541748046875, accuracy = 1.0\n",
            "Batch 60: Loss = 0.5785398483276367, accuracy = 0.875\n",
            "Batch 70: Loss = 0.29334330558776855, accuracy = 0.875\n",
            "Batch 80: Loss = 0.35071372985839844, accuracy = 0.75\n",
            "Batch 90: Loss = 0.0561065673828125, accuracy = 1.0\n",
            "Batch 100: Loss = 0.18025970458984375, accuracy = 1.0\n",
            "Batch 110: Loss = 1.0934200286865234, accuracy = 0.5\n",
            "Validation: Loss = 0.8909507299724378, accuracy = 0.6974789915966386\n",
            "======== Epoch: 63 ========\n",
            "Batch 10: Loss = 0.14030933380126953, accuracy = 1.0\n",
            "Batch 20: Loss = 0.20321154594421387, accuracy = 0.875\n",
            "Batch 30: Loss = 0.09787988662719727, accuracy = 1.0\n",
            "Batch 40: Loss = 0.4767441749572754, accuracy = 0.875\n",
            "Batch 50: Loss = 0.3973712921142578, accuracy = 0.875\n",
            "Batch 60: Loss = 0.26366233825683594, accuracy = 0.875\n",
            "Batch 70: Loss = 0.6768479347229004, accuracy = 0.75\n",
            "Batch 80: Loss = 0.3934214115142822, accuracy = 0.75\n",
            "Batch 90: Loss = 0.157196044921875, accuracy = 1.0\n",
            "Batch 100: Loss = 0.26730918884277344, accuracy = 0.875\n",
            "Batch 110: Loss = 0.6210422515869141, accuracy = 0.75\n",
            "Validation: Loss = 0.8903380067724931, accuracy = 0.7226890756302521\n",
            "======== Epoch: 64 ========\n",
            "Batch 10: Loss = 0.12222146987915039, accuracy = 1.0\n",
            "Batch 20: Loss = 0.712773323059082, accuracy = 0.875\n",
            "Batch 30: Loss = 0.17309808731079102, accuracy = 1.0\n",
            "Batch 40: Loss = 0.23480653762817383, accuracy = 0.875\n",
            "Batch 50: Loss = 0.1631608009338379, accuracy = 0.875\n",
            "Batch 60: Loss = 0.28329944610595703, accuracy = 0.875\n",
            "Batch 70: Loss = 0.8240022659301758, accuracy = 0.75\n",
            "Batch 80: Loss = 0.14786338806152344, accuracy = 1.0\n",
            "Batch 90: Loss = 0.13697433471679688, accuracy = 1.0\n",
            "Batch 100: Loss = 0.7567367553710938, accuracy = 0.625\n",
            "Batch 110: Loss = 0.49173450469970703, accuracy = 0.875\n",
            "Validation: Loss = 0.9060052110437762, accuracy = 0.7226890756302521\n",
            "======== Epoch: 65 ========\n",
            "Batch 10: Loss = 0.3135185241699219, accuracy = 1.0\n",
            "Batch 20: Loss = 0.21574878692626953, accuracy = 1.0\n",
            "Batch 30: Loss = 0.4766426086425781, accuracy = 0.875\n",
            "Batch 40: Loss = 0.10211324691772461, accuracy = 1.0\n",
            "Batch 50: Loss = 1.0306816101074219, accuracy = 0.625\n",
            "Batch 60: Loss = 0.2602677345275879, accuracy = 1.0\n",
            "Batch 70: Loss = 0.4127845764160156, accuracy = 0.75\n",
            "Batch 80: Loss = 0.6325912475585938, accuracy = 0.75\n",
            "Batch 90: Loss = 0.06021833419799805, accuracy = 1.0\n",
            "Batch 100: Loss = 0.4024200439453125, accuracy = 0.875\n",
            "Batch 110: Loss = 1.0443572998046875, accuracy = 0.5\n",
            "Validation: Loss = 0.9061636882915831, accuracy = 0.7142857142857143\n",
            "======== Epoch: 66 ========\n",
            "Batch 10: Loss = 0.107704758644104, accuracy = 1.0\n",
            "Batch 20: Loss = 0.4729318618774414, accuracy = 0.875\n",
            "Batch 30: Loss = 0.13706445693969727, accuracy = 1.0\n",
            "Batch 40: Loss = 0.4552879333496094, accuracy = 0.875\n",
            "Batch 50: Loss = 0.3459014892578125, accuracy = 0.75\n",
            "Batch 60: Loss = 0.5536727905273438, accuracy = 0.875\n",
            "Batch 70: Loss = 0.4325065612792969, accuracy = 0.875\n",
            "Batch 80: Loss = 0.7774701118469238, accuracy = 0.75\n",
            "Batch 90: Loss = 0.2593827247619629, accuracy = 1.0\n",
            "Batch 100: Loss = 0.24357986450195312, accuracy = 0.875\n",
            "Batch 110: Loss = 0.14040803909301758, accuracy = 1.0\n",
            "Validation: Loss = 0.8848663087476764, accuracy = 0.7310924369747899\n",
            "======== Epoch: 67 ========\n",
            "Batch 10: Loss = 0.44433116912841797, accuracy = 0.875\n",
            "Batch 20: Loss = 0.11315298080444336, accuracy = 1.0\n",
            "Batch 30: Loss = 0.047192931175231934, accuracy = 1.0\n",
            "Batch 40: Loss = 0.12996959686279297, accuracy = 1.0\n",
            "Batch 50: Loss = 0.18748140335083008, accuracy = 0.875\n",
            "Batch 60: Loss = 0.15125298500061035, accuracy = 1.0\n",
            "Batch 70: Loss = 0.43193531036376953, accuracy = 0.75\n",
            "Batch 80: Loss = 0.41140425205230713, accuracy = 0.875\n",
            "Batch 90: Loss = 0.27025890350341797, accuracy = 0.875\n",
            "Batch 100: Loss = 0.6803245544433594, accuracy = 0.875\n",
            "Batch 110: Loss = 0.2695894241333008, accuracy = 0.875\n",
            "Validation: Loss = 0.8925834664127283, accuracy = 0.7394957983193278\n",
            "======== Epoch: 68 ========\n",
            "Batch 10: Loss = 0.5352439880371094, accuracy = 0.875\n",
            "Batch 20: Loss = 0.43971920013427734, accuracy = 0.875\n",
            "Batch 30: Loss = 0.06884479522705078, accuracy = 1.0\n",
            "Batch 40: Loss = 0.2604050636291504, accuracy = 1.0\n",
            "Batch 50: Loss = 0.20624732971191406, accuracy = 1.0\n",
            "Batch 60: Loss = 0.3400411605834961, accuracy = 1.0\n",
            "Batch 70: Loss = 0.3541245460510254, accuracy = 0.875\n",
            "Batch 80: Loss = 0.20495092868804932, accuracy = 0.875\n",
            "Batch 90: Loss = 0.24213218688964844, accuracy = 0.875\n",
            "Batch 100: Loss = 0.09862613677978516, accuracy = 1.0\n",
            "Batch 110: Loss = 0.6774263381958008, accuracy = 0.875\n",
            "Validation: Loss = 0.8642502040193792, accuracy = 0.7394957983193278\n",
            "======== Epoch: 69 ========\n",
            "Batch 10: Loss = 0.8407363891601562, accuracy = 0.625\n",
            "Batch 20: Loss = 1.3014907836914062, accuracy = 0.5\n",
            "Batch 30: Loss = 0.12623834609985352, accuracy = 1.0\n",
            "Batch 40: Loss = 0.5061092376708984, accuracy = 0.75\n",
            "Batch 50: Loss = 0.2586793899536133, accuracy = 1.0\n",
            "Batch 60: Loss = 0.4680919647216797, accuracy = 0.875\n",
            "Batch 70: Loss = 0.16846752166748047, accuracy = 1.0\n",
            "Batch 80: Loss = 0.3162212371826172, accuracy = 1.0\n",
            "Batch 90: Loss = 0.8309307098388672, accuracy = 0.5\n",
            "Batch 100: Loss = 0.3171882629394531, accuracy = 1.0\n",
            "Batch 110: Loss = 0.0719900131225586, accuracy = 1.0\n",
            "Validation: Loss = 0.9024011294047037, accuracy = 0.7142857142857143\n",
            "======== Epoch: 70 ========\n",
            "Batch 10: Loss = 0.41234779357910156, accuracy = 0.875\n",
            "Batch 20: Loss = 0.515960693359375, accuracy = 0.75\n",
            "Batch 30: Loss = 0.37137508392333984, accuracy = 0.875\n",
            "Batch 40: Loss = 0.5854346752166748, accuracy = 0.875\n",
            "Batch 50: Loss = 0.11541604995727539, accuracy = 0.875\n",
            "Batch 60: Loss = 0.5295467376708984, accuracy = 0.875\n",
            "Batch 70: Loss = 0.11199784278869629, accuracy = 1.0\n",
            "Batch 80: Loss = 0.2786989212036133, accuracy = 0.875\n",
            "Batch 90: Loss = 0.4564476013183594, accuracy = 0.875\n",
            "Batch 100: Loss = 0.3545083999633789, accuracy = 0.875\n",
            "Batch 110: Loss = 0.37700605392456055, accuracy = 0.875\n",
            "Validation: Loss = 0.8812617000780607, accuracy = 0.7226890756302521\n",
            "======== Epoch: 71 ========\n",
            "Batch 10: Loss = 0.7448501586914062, accuracy = 0.875\n",
            "Batch 20: Loss = 0.22201251983642578, accuracy = 0.875\n",
            "Batch 30: Loss = 0.3336615562438965, accuracy = 1.0\n",
            "Batch 40: Loss = 0.5694201588630676, accuracy = 0.75\n",
            "Batch 50: Loss = 0.4518589973449707, accuracy = 0.875\n",
            "Batch 60: Loss = 0.5659496784210205, accuracy = 0.625\n",
            "Batch 70: Loss = 1.1533093452453613, accuracy = 0.625\n",
            "Batch 80: Loss = 0.31893157958984375, accuracy = 0.875\n",
            "Batch 90: Loss = 0.3347468376159668, accuracy = 0.875\n",
            "Batch 100: Loss = 0.8192567825317383, accuracy = 0.625\n",
            "Batch 110: Loss = 0.8332371711730957, accuracy = 0.75\n",
            "Validation: Loss = 0.8771349463546485, accuracy = 0.7226890756302521\n",
            "======== Epoch: 72 ========\n",
            "Batch 10: Loss = 0.5841898918151855, accuracy = 0.875\n",
            "Batch 20: Loss = 0.42948198318481445, accuracy = 0.875\n",
            "Batch 30: Loss = 0.5292091369628906, accuracy = 0.875\n",
            "Batch 40: Loss = 0.6937005519866943, accuracy = 0.875\n",
            "Batch 50: Loss = 0.16584396362304688, accuracy = 1.0\n",
            "Batch 60: Loss = 0.07982730865478516, accuracy = 1.0\n",
            "Batch 70: Loss = 0.7188014984130859, accuracy = 0.75\n",
            "Batch 80: Loss = 0.2836618423461914, accuracy = 1.0\n",
            "Batch 90: Loss = 0.5549712181091309, accuracy = 0.875\n",
            "Batch 100: Loss = 0.4776611328125, accuracy = 0.875\n",
            "Batch 110: Loss = 0.32423973083496094, accuracy = 0.875\n",
            "Validation: Loss = 0.8918691267047012, accuracy = 0.7310924369747899\n",
            "======== Epoch: 73 ========\n",
            "Batch 10: Loss = 0.8226954936981201, accuracy = 0.5\n",
            "Batch 20: Loss = 0.5523281097412109, accuracy = 0.875\n",
            "Batch 30: Loss = 0.34626007080078125, accuracy = 1.0\n",
            "Batch 40: Loss = 0.3922128677368164, accuracy = 0.875\n",
            "Batch 50: Loss = 0.05493927001953125, accuracy = 1.0\n",
            "Batch 60: Loss = 0.13997888565063477, accuracy = 1.0\n",
            "Batch 70: Loss = 0.4479961395263672, accuracy = 0.875\n",
            "Batch 80: Loss = 0.8325939178466797, accuracy = 0.75\n",
            "Batch 90: Loss = 0.3619041442871094, accuracy = 0.875\n",
            "Batch 100: Loss = 0.6718690395355225, accuracy = 0.5\n",
            "Batch 110: Loss = 0.7991466522216797, accuracy = 0.625\n",
            "Validation: Loss = 0.8851941217455948, accuracy = 0.7310924369747899\n",
            "======== Epoch: 74 ========\n",
            "Batch 10: Loss = 0.1661672592163086, accuracy = 1.0\n",
            "Batch 20: Loss = 0.2302909791469574, accuracy = 0.875\n",
            "Batch 30: Loss = 0.11726963520050049, accuracy = 1.0\n",
            "Batch 40: Loss = 0.1540980339050293, accuracy = 1.0\n",
            "Batch 50: Loss = 0.5819358229637146, accuracy = 0.75\n",
            "Batch 60: Loss = 0.8127985000610352, accuracy = 0.625\n",
            "Batch 70: Loss = 0.309146523475647, accuracy = 0.875\n",
            "Batch 80: Loss = 0.08960747718811035, accuracy = 1.0\n",
            "Batch 90: Loss = 0.4430723190307617, accuracy = 0.875\n",
            "Batch 100: Loss = 0.3198251724243164, accuracy = 1.0\n",
            "Batch 110: Loss = 0.5641202926635742, accuracy = 0.75\n",
            "Validation: Loss = 0.8946585780695865, accuracy = 0.7310924369747899\n",
            "======== Epoch: 75 ========\n",
            "Batch 10: Loss = 0.4502105712890625, accuracy = 0.75\n",
            "Batch 20: Loss = 0.28399980068206787, accuracy = 0.875\n",
            "Batch 30: Loss = 0.16297435760498047, accuracy = 0.875\n",
            "Batch 40: Loss = 0.3024301528930664, accuracy = 1.0\n",
            "Batch 50: Loss = 0.3598651885986328, accuracy = 1.0\n",
            "Batch 60: Loss = 0.9988820552825928, accuracy = 0.75\n",
            "Batch 70: Loss = 0.3247098922729492, accuracy = 0.875\n",
            "Batch 80: Loss = 0.2931632995605469, accuracy = 1.0\n",
            "Batch 90: Loss = 0.1422572135925293, accuracy = 1.0\n",
            "Batch 100: Loss = 0.3332996368408203, accuracy = 0.875\n",
            "Batch 110: Loss = 0.6168479919433594, accuracy = 0.875\n",
            "Validation: Loss = 0.877849072740789, accuracy = 0.7478991596638656\n",
            "======== Epoch: 76 ========\n",
            "Batch 10: Loss = 0.2382657527923584, accuracy = 0.875\n",
            "Batch 20: Loss = 0.2850971221923828, accuracy = 1.0\n",
            "Batch 30: Loss = 0.28973388671875, accuracy = 1.0\n",
            "Batch 40: Loss = 0.22259080410003662, accuracy = 0.875\n",
            "Batch 50: Loss = 0.06109809875488281, accuracy = 1.0\n",
            "Batch 60: Loss = 0.3019595146179199, accuracy = 0.875\n",
            "Batch 70: Loss = 0.6009836196899414, accuracy = 0.75\n",
            "Batch 80: Loss = 0.45107269287109375, accuracy = 0.875\n",
            "Batch 90: Loss = 0.08180093765258789, accuracy = 1.0\n",
            "Batch 100: Loss = 0.14051532745361328, accuracy = 1.0\n",
            "Batch 110: Loss = 0.1667006015777588, accuracy = 1.0\n",
            "Validation: Loss = 0.8790660490069473, accuracy = 0.7226890756302521\n",
            "======== Epoch: 77 ========\n",
            "Batch 10: Loss = 0.27607905864715576, accuracy = 0.875\n",
            "Batch 20: Loss = 0.3823375701904297, accuracy = 0.875\n",
            "Batch 30: Loss = 0.10002791881561279, accuracy = 1.0\n",
            "Batch 40: Loss = 0.6117630004882812, accuracy = 0.75\n",
            "Batch 50: Loss = 0.5707821846008301, accuracy = 0.75\n",
            "Batch 60: Loss = 0.4521050453186035, accuracy = 0.875\n",
            "Batch 70: Loss = 0.22413063049316406, accuracy = 0.875\n",
            "Batch 80: Loss = 0.4275853633880615, accuracy = 0.875\n",
            "Batch 90: Loss = 0.4627823829650879, accuracy = 0.875\n",
            "Batch 100: Loss = 0.266265869140625, accuracy = 1.0\n",
            "Batch 110: Loss = 0.33899831771850586, accuracy = 0.875\n",
            "Validation: Loss = 0.894750762404057, accuracy = 0.7142857142857143\n",
            "======== Epoch: 78 ========\n",
            "Batch 10: Loss = 0.34626340866088867, accuracy = 0.875\n",
            "Batch 20: Loss = 0.36780357360839844, accuracy = 0.875\n",
            "Batch 30: Loss = 0.1714315414428711, accuracy = 1.0\n",
            "Batch 40: Loss = 0.5374259948730469, accuracy = 0.875\n",
            "Batch 50: Loss = 0.05927920341491699, accuracy = 1.0\n",
            "Batch 60: Loss = 0.4614882469177246, accuracy = 0.75\n",
            "Batch 70: Loss = 0.42492008209228516, accuracy = 0.875\n",
            "Batch 80: Loss = 0.8871612548828125, accuracy = 0.75\n",
            "Batch 90: Loss = 0.06582450866699219, accuracy = 1.0\n",
            "Batch 100: Loss = 0.8142309188842773, accuracy = 0.875\n",
            "Batch 110: Loss = 0.25097644329071045, accuracy = 0.875\n",
            "Validation: Loss = 0.8804090357663339, accuracy = 0.7310924369747899\n",
            "======== Epoch: 79 ========\n",
            "Batch 10: Loss = 0.7943010330200195, accuracy = 0.625\n",
            "Batch 20: Loss = 0.21886205673217773, accuracy = 1.0\n",
            "Batch 30: Loss = 0.17705392837524414, accuracy = 1.0\n",
            "Batch 40: Loss = 0.5363445281982422, accuracy = 0.75\n",
            "Batch 50: Loss = 0.5405502319335938, accuracy = 0.75\n",
            "Batch 60: Loss = 0.0593717098236084, accuracy = 1.0\n",
            "Batch 70: Loss = 0.47127771377563477, accuracy = 0.875\n",
            "Batch 80: Loss = 0.5158462524414062, accuracy = 0.75\n",
            "Batch 90: Loss = 0.45385587215423584, accuracy = 0.875\n",
            "Batch 100: Loss = 0.6507997512817383, accuracy = 0.875\n",
            "Batch 110: Loss = 0.41698646545410156, accuracy = 0.75\n",
            "Validation: Loss = 0.8941201034345125, accuracy = 0.7394957983193278\n",
            "======== Epoch: 80 ========\n",
            "Batch 10: Loss = 0.17393922805786133, accuracy = 1.0\n",
            "Batch 20: Loss = 0.4181404113769531, accuracy = 0.75\n",
            "Batch 30: Loss = 0.246337890625, accuracy = 0.875\n",
            "Batch 40: Loss = 0.2208695411682129, accuracy = 0.875\n",
            "Batch 50: Loss = 0.12737274169921875, accuracy = 1.0\n",
            "Batch 60: Loss = 0.4753580093383789, accuracy = 0.75\n",
            "Batch 70: Loss = 0.6369895935058594, accuracy = 0.875\n",
            "Batch 80: Loss = 0.4110281467437744, accuracy = 0.75\n",
            "Batch 90: Loss = 0.7020606994628906, accuracy = 0.75\n",
            "Batch 100: Loss = 0.8754878044128418, accuracy = 0.625\n",
            "Batch 110: Loss = 0.20664405822753906, accuracy = 0.875\n",
            "Validation: Loss = 0.8923277018363016, accuracy = 0.7310924369747899\n",
            "======== Epoch: 81 ========\n",
            "Batch 10: Loss = 0.3012228012084961, accuracy = 0.875\n",
            "Batch 20: Loss = 0.14947491884231567, accuracy = 1.0\n",
            "Batch 30: Loss = 0.058991432189941406, accuracy = 1.0\n",
            "Batch 40: Loss = 0.8766250610351562, accuracy = 0.625\n",
            "Batch 50: Loss = 0.11649751663208008, accuracy = 1.0\n",
            "Batch 60: Loss = 0.28261518478393555, accuracy = 0.875\n",
            "Batch 70: Loss = 0.42609691619873047, accuracy = 0.875\n",
            "Batch 80: Loss = 0.05253958702087402, accuracy = 1.0\n",
            "Batch 90: Loss = 0.8502216339111328, accuracy = 0.75\n",
            "Batch 100: Loss = 0.339343786239624, accuracy = 0.875\n",
            "Batch 110: Loss = 0.8140544891357422, accuracy = 0.75\n",
            "Validation: Loss = 0.8865730427859122, accuracy = 0.7394957983193278\n",
            "======== Epoch: 82 ========\n",
            "Batch 10: Loss = 0.23521065711975098, accuracy = 0.875\n",
            "Batch 20: Loss = 0.33808577060699463, accuracy = 0.875\n",
            "Batch 30: Loss = 0.18294715881347656, accuracy = 1.0\n",
            "Batch 40: Loss = 0.1273496150970459, accuracy = 1.0\n",
            "Batch 50: Loss = 0.43572998046875, accuracy = 0.875\n",
            "Batch 60: Loss = 0.39668941497802734, accuracy = 0.875\n",
            "Batch 70: Loss = 0.3253669738769531, accuracy = 0.875\n",
            "Batch 80: Loss = 0.23288369178771973, accuracy = 1.0\n",
            "Batch 90: Loss = 0.19783782958984375, accuracy = 1.0\n",
            "Batch 100: Loss = 0.13460683822631836, accuracy = 1.0\n",
            "Batch 110: Loss = 0.22441387176513672, accuracy = 1.0\n",
            "Validation: Loss = 0.8846923510233561, accuracy = 0.7478991596638656\n",
            "======== Epoch: 83 ========\n",
            "Batch 10: Loss = 0.23404908180236816, accuracy = 0.875\n",
            "Batch 20: Loss = 0.2465667724609375, accuracy = 0.875\n",
            "Batch 30: Loss = 0.1879723072052002, accuracy = 1.0\n",
            "Batch 40: Loss = 0.0949714183807373, accuracy = 1.0\n",
            "Batch 50: Loss = 0.14664745330810547, accuracy = 1.0\n",
            "Batch 60: Loss = 0.25491786003112793, accuracy = 0.875\n",
            "Batch 70: Loss = 0.2752218246459961, accuracy = 0.875\n",
            "Batch 80: Loss = 0.11532402038574219, accuracy = 1.0\n",
            "Batch 90: Loss = 0.043849825859069824, accuracy = 1.0\n",
            "Batch 100: Loss = 0.09094810485839844, accuracy = 1.0\n",
            "Batch 110: Loss = 0.6466445922851562, accuracy = 0.625\n",
            "Validation: Loss = 0.8767685681058649, accuracy = 0.7394957983193278\n",
            "======== Epoch: 84 ========\n",
            "Batch 10: Loss = 0.30306434631347656, accuracy = 1.0\n",
            "Batch 20: Loss = 0.25563836097717285, accuracy = 0.875\n",
            "Batch 30: Loss = 0.7582950592041016, accuracy = 0.625\n",
            "Batch 40: Loss = 0.7906064391136169, accuracy = 0.5\n",
            "Batch 50: Loss = 0.6981325149536133, accuracy = 0.5\n",
            "Batch 60: Loss = 0.4077720642089844, accuracy = 0.875\n",
            "Batch 70: Loss = 0.2635049819946289, accuracy = 0.875\n",
            "Batch 80: Loss = 0.21671676635742188, accuracy = 0.875\n",
            "Batch 90: Loss = 0.05562591552734375, accuracy = 1.0\n",
            "Batch 100: Loss = 0.2668907642364502, accuracy = 0.875\n",
            "Batch 110: Loss = 0.16327476501464844, accuracy = 1.0\n",
            "Validation: Loss = 0.8851981413991827, accuracy = 0.7394957983193278\n",
            "======== Epoch: 85 ========\n",
            "Batch 10: Loss = 0.1143808364868164, accuracy = 1.0\n",
            "Batch 20: Loss = 0.06943035125732422, accuracy = 1.0\n",
            "Batch 30: Loss = 0.47542762756347656, accuracy = 0.75\n",
            "Batch 40: Loss = 0.6833734512329102, accuracy = 0.75\n",
            "Batch 50: Loss = 0.16740798950195312, accuracy = 1.0\n",
            "Batch 60: Loss = 0.3658313751220703, accuracy = 0.875\n",
            "Batch 70: Loss = 0.10969400405883789, accuracy = 1.0\n",
            "Batch 80: Loss = 0.9657192230224609, accuracy = 0.625\n",
            "Batch 90: Loss = 0.17616701126098633, accuracy = 1.0\n",
            "Batch 100: Loss = 0.8685934543609619, accuracy = 0.375\n",
            "Batch 110: Loss = 0.09786605834960938, accuracy = 1.0\n",
            "Validation: Loss = 0.8814900297867624, accuracy = 0.7478991596638656\n",
            "======== Epoch: 86 ========\n",
            "Batch 10: Loss = 0.41860294342041016, accuracy = 0.875\n",
            "Batch 20: Loss = 0.7176246643066406, accuracy = 0.75\n",
            "Batch 30: Loss = 0.3009079098701477, accuracy = 0.875\n",
            "Batch 40: Loss = 0.18746662139892578, accuracy = 0.875\n",
            "Batch 50: Loss = 0.16135787963867188, accuracy = 1.0\n",
            "Batch 60: Loss = 0.12242269515991211, accuracy = 1.0\n",
            "Batch 70: Loss = 0.25055694580078125, accuracy = 0.875\n",
            "Batch 80: Loss = 0.29719996452331543, accuracy = 1.0\n",
            "Batch 90: Loss = 0.47905540466308594, accuracy = 0.875\n",
            "Batch 100: Loss = 0.5104930400848389, accuracy = 0.75\n",
            "Batch 110: Loss = 1.5219497680664062, accuracy = 0.5\n",
            "Validation: Loss = 0.8884253292752985, accuracy = 0.7478991596638656\n",
            "======== Epoch: 87 ========\n",
            "Batch 10: Loss = 0.19784069061279297, accuracy = 1.0\n",
            "Batch 20: Loss = 0.05437874794006348, accuracy = 1.0\n",
            "Batch 30: Loss = 1.058237075805664, accuracy = 0.75\n",
            "Batch 40: Loss = 0.36106109619140625, accuracy = 0.875\n",
            "Batch 50: Loss = 0.11056756973266602, accuracy = 1.0\n",
            "Batch 60: Loss = 0.4240856170654297, accuracy = 0.75\n",
            "Batch 70: Loss = 0.38154125213623047, accuracy = 0.875\n",
            "Batch 80: Loss = 0.103973388671875, accuracy = 1.0\n",
            "Batch 90: Loss = 0.09246492385864258, accuracy = 1.0\n",
            "Batch 100: Loss = 0.27124786376953125, accuracy = 0.875\n",
            "Batch 110: Loss = 0.24530982971191406, accuracy = 0.875\n",
            "Validation: Loss = 0.8780822335628041, accuracy = 0.7394957983193278\n",
            "======== Epoch: 88 ========\n",
            "Batch 10: Loss = 0.5216836929321289, accuracy = 0.875\n",
            "Batch 20: Loss = 0.4606294631958008, accuracy = 0.75\n",
            "Batch 30: Loss = 0.05066800117492676, accuracy = 1.0\n",
            "Batch 40: Loss = 0.48963069915771484, accuracy = 0.875\n",
            "Batch 50: Loss = 0.20562505722045898, accuracy = 1.0\n",
            "Batch 60: Loss = 0.5181059837341309, accuracy = 0.875\n",
            "Batch 70: Loss = 0.3896167278289795, accuracy = 0.875\n",
            "Batch 80: Loss = 1.0116944313049316, accuracy = 0.625\n",
            "Batch 90: Loss = 0.6576204299926758, accuracy = 0.75\n",
            "Batch 100: Loss = 0.8139638900756836, accuracy = 0.75\n",
            "Batch 110: Loss = 0.3452615737915039, accuracy = 0.875\n",
            "Validation: Loss = 0.8896237967307108, accuracy = 0.7394957983193278\n",
            "======== Epoch: 89 ========\n",
            "Batch 10: Loss = 0.4099082946777344, accuracy = 0.875\n",
            "Batch 20: Loss = 0.2652583122253418, accuracy = 0.875\n",
            "Batch 30: Loss = 0.35282468795776367, accuracy = 0.875\n",
            "Batch 40: Loss = 0.36002445220947266, accuracy = 0.875\n",
            "Batch 50: Loss = 0.515324592590332, accuracy = 0.625\n",
            "Batch 60: Loss = 0.11249494552612305, accuracy = 1.0\n",
            "Batch 70: Loss = 0.23952579498291016, accuracy = 0.875\n",
            "Batch 80: Loss = 0.16373825073242188, accuracy = 1.0\n",
            "Batch 90: Loss = 0.05446910858154297, accuracy = 1.0\n",
            "Batch 100: Loss = 0.2613258361816406, accuracy = 0.875\n",
            "Batch 110: Loss = 0.3535938262939453, accuracy = 0.875\n",
            "Validation: Loss = 0.8864051919234427, accuracy = 0.7394957983193278\n",
            "======== Epoch: 90 ========\n",
            "Batch 10: Loss = 0.2748394012451172, accuracy = 1.0\n",
            "Batch 20: Loss = 0.7199001312255859, accuracy = 0.75\n",
            "Batch 30: Loss = 0.20408248901367188, accuracy = 1.0\n",
            "Batch 40: Loss = 0.2488703727722168, accuracy = 1.0\n",
            "Batch 50: Loss = 0.2809906005859375, accuracy = 1.0\n",
            "Batch 60: Loss = 0.108001708984375, accuracy = 1.0\n",
            "Batch 70: Loss = 0.1367168426513672, accuracy = 1.0\n",
            "Batch 80: Loss = 0.13429701328277588, accuracy = 1.0\n",
            "Batch 90: Loss = 0.5862207412719727, accuracy = 0.875\n",
            "Batch 100: Loss = 0.41887950897216797, accuracy = 0.875\n",
            "Batch 110: Loss = 1.1374149322509766, accuracy = 0.625\n",
            "Validation: Loss = 0.8829920919317948, accuracy = 0.7394957983193278\n",
            "======== Epoch: 91 ========\n",
            "Batch 10: Loss = 0.1380326747894287, accuracy = 0.875\n",
            "Batch 20: Loss = 0.14548301696777344, accuracy = 1.0\n",
            "Batch 30: Loss = 0.9459686279296875, accuracy = 0.625\n",
            "Batch 40: Loss = 0.20573723316192627, accuracy = 0.875\n",
            "Batch 50: Loss = 0.2722434997558594, accuracy = 0.875\n",
            "Batch 60: Loss = 0.413177490234375, accuracy = 0.875\n",
            "Batch 70: Loss = 0.23540878295898438, accuracy = 0.875\n",
            "Batch 80: Loss = 0.18492507934570312, accuracy = 0.875\n",
            "Batch 90: Loss = 0.6776676177978516, accuracy = 0.75\n",
            "Batch 100: Loss = 0.11927509307861328, accuracy = 1.0\n",
            "Batch 110: Loss = 0.3581085205078125, accuracy = 0.875\n",
            "Validation: Loss = 0.8848343020991275, accuracy = 0.7310924369747899\n",
            "======== Epoch: 92 ========\n",
            "Batch 10: Loss = 0.5391372442245483, accuracy = 0.875\n",
            "Batch 20: Loss = 0.7500290870666504, accuracy = 0.75\n",
            "Batch 30: Loss = 0.4200935363769531, accuracy = 0.75\n",
            "Batch 40: Loss = 0.1661396026611328, accuracy = 1.0\n",
            "Batch 50: Loss = 0.22569668292999268, accuracy = 1.0\n",
            "Batch 60: Loss = 0.8744544982910156, accuracy = 0.625\n",
            "Batch 70: Loss = 0.23549175262451172, accuracy = 1.0\n",
            "Batch 80: Loss = 0.20024871826171875, accuracy = 1.0\n",
            "Batch 90: Loss = 0.32735252380371094, accuracy = 0.75\n",
            "Batch 100: Loss = 0.09934186935424805, accuracy = 1.0\n",
            "Batch 110: Loss = 0.45673370361328125, accuracy = 0.75\n",
            "Validation: Loss = 0.894009836933069, accuracy = 0.7310924369747899\n",
            "======== Epoch: 93 ========\n",
            "Batch 10: Loss = 0.08495950698852539, accuracy = 1.0\n",
            "Batch 20: Loss = 0.172393798828125, accuracy = 1.0\n",
            "Batch 30: Loss = 0.2917238473892212, accuracy = 0.875\n",
            "Batch 40: Loss = 0.7306057214736938, accuracy = 0.625\n",
            "Batch 50: Loss = 0.2863454818725586, accuracy = 0.875\n",
            "Batch 60: Loss = 0.2982909679412842, accuracy = 0.875\n",
            "Batch 70: Loss = 0.22807800769805908, accuracy = 1.0\n",
            "Batch 80: Loss = 0.0831298828125, accuracy = 1.0\n",
            "Batch 90: Loss = 0.33138275146484375, accuracy = 0.875\n",
            "Batch 100: Loss = 0.44541966915130615, accuracy = 0.625\n",
            "Batch 110: Loss = 0.27811717987060547, accuracy = 0.875\n",
            "Validation: Loss = 0.8800864596115915, accuracy = 0.7310924369747899\n",
            "======== Epoch: 94 ========\n",
            "Batch 10: Loss = 0.13474655151367188, accuracy = 1.0\n",
            "Batch 20: Loss = 0.36457252502441406, accuracy = 0.875\n",
            "Batch 30: Loss = 0.24898171424865723, accuracy = 0.875\n",
            "Batch 40: Loss = 0.29450523853302, accuracy = 0.875\n",
            "Batch 50: Loss = 0.4157562255859375, accuracy = 0.875\n",
            "Batch 60: Loss = 0.30842018127441406, accuracy = 0.875\n",
            "Batch 70: Loss = 0.25829124450683594, accuracy = 0.875\n",
            "Batch 80: Loss = 0.8247098922729492, accuracy = 0.625\n",
            "Batch 90: Loss = 0.5668678283691406, accuracy = 0.875\n",
            "Batch 100: Loss = 0.6479834318161011, accuracy = 0.625\n",
            "Batch 110: Loss = 0.3915829658508301, accuracy = 0.875\n",
            "Validation: Loss = 0.8806544814193458, accuracy = 0.7310924369747899\n",
            "======== Epoch: 95 ========\n",
            "Batch 10: Loss = 0.13737308979034424, accuracy = 1.0\n",
            "Batch 20: Loss = 0.090087890625, accuracy = 1.0\n",
            "Batch 30: Loss = 0.6620521545410156, accuracy = 0.875\n",
            "Batch 40: Loss = 1.2999839782714844, accuracy = 0.625\n",
            "Batch 50: Loss = 0.5567531585693359, accuracy = 0.75\n",
            "Batch 60: Loss = 0.493896484375, accuracy = 0.75\n",
            "Batch 70: Loss = 0.6609835624694824, accuracy = 0.875\n",
            "Batch 80: Loss = 0.2781085968017578, accuracy = 0.875\n",
            "Batch 90: Loss = 0.28873205184936523, accuracy = 1.0\n",
            "Batch 100: Loss = 0.43846678733825684, accuracy = 0.875\n",
            "Batch 110: Loss = 0.34229040145874023, accuracy = 0.875\n",
            "Validation: Loss = 0.889674324738352, accuracy = 0.7310924369747899\n",
            "======== Epoch: 96 ========\n",
            "Batch 10: Loss = 0.11866378784179688, accuracy = 1.0\n",
            "Batch 20: Loss = 0.2750239372253418, accuracy = 0.875\n",
            "Batch 30: Loss = 0.8671984672546387, accuracy = 0.5\n",
            "Batch 40: Loss = 0.5608987808227539, accuracy = 0.875\n",
            "Batch 50: Loss = 0.09428930282592773, accuracy = 1.0\n",
            "Batch 60: Loss = 0.3471102714538574, accuracy = 0.875\n",
            "Batch 70: Loss = 0.44526004791259766, accuracy = 0.75\n",
            "Batch 80: Loss = 0.7817564010620117, accuracy = 0.875\n",
            "Batch 90: Loss = 0.42892885208129883, accuracy = 0.875\n",
            "Batch 100: Loss = 0.293515682220459, accuracy = 0.875\n",
            "Batch 110: Loss = 0.8505902290344238, accuracy = 0.75\n",
            "Validation: Loss = 0.8891078296460604, accuracy = 0.7394957983193278\n",
            "======== Epoch: 97 ========\n",
            "Batch 10: Loss = 0.7044010162353516, accuracy = 0.875\n",
            "Batch 20: Loss = 0.5653860569000244, accuracy = 0.75\n",
            "Batch 30: Loss = 0.7660026550292969, accuracy = 0.625\n",
            "Batch 40: Loss = 0.2995491027832031, accuracy = 1.0\n",
            "Batch 50: Loss = 0.11799979209899902, accuracy = 1.0\n",
            "Batch 60: Loss = 0.29024505615234375, accuracy = 1.0\n",
            "Batch 70: Loss = 0.3088315725326538, accuracy = 1.0\n",
            "Batch 80: Loss = 1.1222610473632812, accuracy = 0.75\n",
            "Batch 90: Loss = 0.2647254467010498, accuracy = 0.875\n",
            "Batch 100: Loss = 0.3969841003417969, accuracy = 0.875\n",
            "Batch 110: Loss = 0.9748992919921875, accuracy = 0.75\n",
            "Validation: Loss = 0.8859657237404271, accuracy = 0.7394957983193278\n",
            "======== Epoch: 98 ========\n",
            "Batch 10: Loss = 0.18880558013916016, accuracy = 0.875\n",
            "Batch 20: Loss = 0.3243136405944824, accuracy = 1.0\n",
            "Batch 30: Loss = 0.2270030975341797, accuracy = 0.875\n",
            "Batch 40: Loss = 1.2469568252563477, accuracy = 0.625\n",
            "Batch 50: Loss = 0.31520986557006836, accuracy = 0.75\n",
            "Batch 60: Loss = 0.7299833297729492, accuracy = 0.625\n",
            "Batch 70: Loss = 0.30756449699401855, accuracy = 0.875\n",
            "Batch 80: Loss = 0.1587446928024292, accuracy = 1.0\n",
            "Batch 90: Loss = 0.28736114501953125, accuracy = 0.875\n",
            "Batch 100: Loss = 0.3066253662109375, accuracy = 1.0\n",
            "Batch 110: Loss = 0.3532588481903076, accuracy = 0.75\n",
            "Validation: Loss = 0.8881284061231112, accuracy = 0.7310924369747899\n",
            "======== Epoch: 99 ========\n",
            "Batch 10: Loss = 0.9593534469604492, accuracy = 0.75\n",
            "Batch 20: Loss = 0.12037324905395508, accuracy = 1.0\n",
            "Batch 30: Loss = 0.5737512111663818, accuracy = 0.75\n",
            "Batch 40: Loss = 0.49571943283081055, accuracy = 0.875\n",
            "Batch 50: Loss = 0.2122185230255127, accuracy = 1.0\n",
            "Batch 60: Loss = 0.30979156494140625, accuracy = 1.0\n",
            "Batch 70: Loss = 0.2954559326171875, accuracy = 0.875\n",
            "Batch 80: Loss = 0.7111568450927734, accuracy = 0.875\n",
            "Batch 90: Loss = 0.06871926784515381, accuracy = 1.0\n",
            "Batch 100: Loss = 0.4737997055053711, accuracy = 0.75\n",
            "Batch 110: Loss = 0.244842529296875, accuracy = 1.0\n",
            "Validation: Loss = 0.8893201434821413, accuracy = 0.7310924369747899\n",
            "======== Epoch: 100 ========\n",
            "Batch 10: Loss = 0.4979400634765625, accuracy = 0.875\n",
            "Batch 20: Loss = 0.4720957279205322, accuracy = 0.875\n",
            "Batch 30: Loss = 0.5599966049194336, accuracy = 0.75\n",
            "Batch 40: Loss = 0.250885009765625, accuracy = 1.0\n",
            "Batch 50: Loss = 0.3891639709472656, accuracy = 0.875\n",
            "Batch 60: Loss = 0.35434138774871826, accuracy = 0.875\n",
            "Batch 70: Loss = 0.0558018684387207, accuracy = 1.0\n",
            "Batch 80: Loss = 0.24051141738891602, accuracy = 1.0\n",
            "Batch 90: Loss = 0.6066513061523438, accuracy = 0.75\n",
            "Batch 100: Loss = 0.5907958745956421, accuracy = 0.875\n",
            "Batch 110: Loss = 0.08945083618164062, accuracy = 1.0\n",
            "Validation: Loss = 0.889718632949026, accuracy = 0.7310924369747899\n",
            "Best accuracy achieved: 0.7478991596638656\n",
            "Corresponding loss:  0.8884253292752985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idq7bkZIwebm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}